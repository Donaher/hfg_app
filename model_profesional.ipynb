{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copia de heart disease.ipynb","version":"0.3.2","provenance":[{"file_id":"1kwPN0sPklZ0zTVpe03QPdtzcpHydLR7I","timestamp":1553246238416}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"toc":true,"id":"50XM2TOtsGR4","colab_type":"text"},"cell_type":"markdown","source":["<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n","<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Carga-de-datos\" data-toc-modified-id=\"Carga-de-datos-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Carga de datos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Nombre-columnas\" data-toc-modified-id=\"Nombre-columnas-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Nombre columnas</a></span></li><li><span><a href=\"#Número-de-columnas\" data-toc-modified-id=\"Número-de-columnas-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Número de columnas</a></span></li><li><span><a href=\"#Preparación-de-los-datos\" data-toc-modified-id=\"Preparación-de-los-datos-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Preparación de los datos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pre-procesamiento\" data-toc-modified-id=\"Pre-procesamiento-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Pre-procesamiento</a></span><ul class=\"toc-item\"><li><span><a href=\"#Normalización-min_max\" data-toc-modified-id=\"Normalización-min_max-1.3.1.1\"><span class=\"toc-item-num\">1.3.1.1&nbsp;&nbsp;</span>Normalización min_max</a></span></li></ul></li><li><span><a href=\"#Definición-de-X-e-y\" data-toc-modified-id=\"Definición-de-X-e-y-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Definición de X e y</a></span></li></ul></li></ul></li><li><span><a href=\"#Definición-del-modelo\" data-toc-modified-id=\"Definición-del-modelo-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Definición del modelo</a></span><ul class=\"toc-item\"><li><span><a href=\"#Entrenamiento-del-modelo\" data-toc-modified-id=\"Entrenamiento-del-modelo-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Entrenamiento del modelo</a></span><ul class=\"toc-item\"><li><span><a href=\"#Learning-rate-schedule\" data-toc-modified-id=\"Learning-rate-schedule-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Learning rate schedule</a></span></li><li><span><a href=\"#Early-Stopping\" data-toc-modified-id=\"Early-Stopping-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Early Stopping</a></span></li><li><span><a href=\"#Model-fit\" data-toc-modified-id=\"Model-fit-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Model fit</a></span></li></ul></li></ul></li><li><span><a href=\"#Model-Evaluation\" data-toc-modified-id=\"Model-Evaluation-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Model Evaluation</a></span></li></ul></div>"]},{"metadata":{"ExecuteTime":{"end_time":"2019-03-18T13:05:52.079561Z","start_time":"2019-03-18T13:05:52.074520Z"},"id":"xnYGp8fRsGR6","colab_type":"code","outputId":"acca09ee-6b9e-4d75-992c-615d22413b5a","executionInfo":{"status":"ok","timestamp":1553306835682,"user_tz":-60,"elapsed":2426,"user":{"displayName":"Francisco del Valle Bas","photoUrl":"","userId":"13762240210727807878"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import pandas as pd\n","\n","import numpy as np\n","\n","import tensorflow as tf\n","\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, Dropout, LSTM, BatchNormalization, GaussianNoise, Flatten, Reshape, Input, MaxPool1D\n","from keras.utils import np_utils\n","from keras.utils import to_categorical\n","from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n","from keras.optimizers import SGD,Adam\n","from keras.regularizers import l2\n","from keras.optimizers import SGD,Adam\n","\n","import keras.layers.advanced_activations as adk\n","\n","from matplotlib import pyplot\n","\n","from sklearn import preprocessing\n","\n","\n","from sklearn.model_selection import train_test_split\n","\n","from keras import regularizers"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"19VQ2v7uu_we","colab_type":"code","outputId":"64f3aae6-af4b-41e8-a0e8-0a61c4240a67","executionInfo":{"status":"ok","timestamp":1553306839541,"user_tz":-60,"elapsed":695,"user":{"displayName":"Francisco del Valle Bas","photoUrl":"","userId":"13762240210727807878"}},"colab":{"base_uri":"https://localhost:8080/","height":1969}},"cell_type":"code","source":["data = pd.read_csv('cardio_train.csv', sep =';').drop(columns=['id'])\n","data"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>gender</th>\n","      <th>height</th>\n","      <th>weight</th>\n","      <th>ap_hi</th>\n","      <th>ap_lo</th>\n","      <th>cholesterol</th>\n","      <th>gluc</th>\n","      <th>smoke</th>\n","      <th>alco</th>\n","      <th>active</th>\n","      <th>cardio</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>18393</td>\n","      <td>2</td>\n","      <td>168</td>\n","      <td>62.0</td>\n","      <td>110</td>\n","      <td>80</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>20228</td>\n","      <td>1</td>\n","      <td>156</td>\n","      <td>85.0</td>\n","      <td>140</td>\n","      <td>90</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>18857</td>\n","      <td>1</td>\n","      <td>165</td>\n","      <td>64.0</td>\n","      <td>130</td>\n","      <td>70</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>17623</td>\n","      <td>2</td>\n","      <td>169</td>\n","      <td>82.0</td>\n","      <td>150</td>\n","      <td>100</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>17474</td>\n","      <td>1</td>\n","      <td>156</td>\n","      <td>56.0</td>\n","      <td>100</td>\n","      <td>60</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>21914</td>\n","      <td>1</td>\n","      <td>151</td>\n","      <td>67.0</td>\n","      <td>120</td>\n","      <td>80</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>22113</td>\n","      <td>1</td>\n","      <td>157</td>\n","      <td>93.0</td>\n","      <td>130</td>\n","      <td>80</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>22584</td>\n","      <td>2</td>\n","      <td>178</td>\n","      <td>95.0</td>\n","      <td>130</td>\n","      <td>90</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>17668</td>\n","      <td>1</td>\n","      <td>158</td>\n","      <td>71.0</td>\n","      <td>110</td>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>19834</td>\n","      <td>1</td>\n","      <td>164</td>\n","      <td>68.0</td>\n","      <td>110</td>\n","      <td>60</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>22530</td>\n","      <td>1</td>\n","      <td>169</td>\n","      <td>80.0</td>\n","      <td>120</td>\n","      <td>80</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>18815</td>\n","      <td>2</td>\n","      <td>173</td>\n","      <td>60.0</td>\n","      <td>120</td>\n","      <td>80</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>14791</td>\n","      <td>2</td>\n","      <td>165</td>\n","      <td>60.0</td>\n","      <td>120</td>\n","      <td>80</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>19809</td>\n","      <td>1</td>\n","      <td>158</td>\n","      <td>78.0</td>\n","      <td>110</td>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>14532</td>\n","      <td>2</td>\n","      <td>181</td>\n","      <td>95.0</td>\n","      <td>130</td>\n","      <td>90</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>16782</td>\n","      <td>2</td>\n","      <td>172</td>\n","      <td>112.0</td>\n","      <td>120</td>\n","      <td>80</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>21296</td>\n","      <td>1</td>\n","      <td>170</td>\n","      <td>75.0</td>\n","      <td>130</td>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>16747</td>\n","      <td>1</td>\n","      <td>158</td>\n","      <td>52.0</td>\n","      <td>110</td>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>17482</td>\n","      <td>1</td>\n","      <td>154</td>\n","      <td>68.0</td>\n","      <td>100</td>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>21755</td>\n","      <td>2</td>\n","      <td>162</td>\n","      <td>56.0</td>\n","      <td>120</td>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>19778</td>\n","      <td>2</td>\n","      <td>163</td>\n","      <td>83.0</td>\n","      <td>120</td>\n","      <td>80</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>21413</td>\n","      <td>1</td>\n","      <td>157</td>\n","      <td>69.0</td>\n","      <td>130</td>\n","      <td>80</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>23046</td>\n","      <td>1</td>\n","      <td>158</td>\n","      <td>90.0</td>\n","      <td>145</td>\n","      <td>85</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>23376</td>\n","      <td>2</td>\n","      <td>156</td>\n","      <td>45.0</td>\n","      <td>110</td>\n","      <td>60</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>16608</td>\n","      <td>1</td>\n","      <td>170</td>\n","      <td>68.0</td>\n","      <td>150</td>\n","      <td>90</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>14453</td>\n","      <td>1</td>\n","      <td>153</td>\n","      <td>65.0</td>\n","      <td>130</td>\n","      <td>100</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>19559</td>\n","      <td>1</td>\n","      <td>156</td>\n","      <td>59.0</td>\n","      <td>130</td>\n","      <td>90</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>18085</td>\n","      <td>1</td>\n","      <td>159</td>\n","      <td>78.0</td>\n","      <td>120</td>\n","      <td>80</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>14574</td>\n","      <td>2</td>\n","      <td>166</td>\n","      <td>66.0</td>\n","      <td>120</td>\n","      <td>80</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>21057</td>\n","      <td>2</td>\n","      <td>169</td>\n","      <td>74.0</td>\n","      <td>130</td>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>69970</th>\n","      <td>22572</td>\n","      <td>2</td>\n","      <td>173</td>\n","      <td>103.0</td>\n","      <td>140</td>\n","      <td>80</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>69971</th>\n","      <td>20136</td>\n","      <td>2</td>\n","      <td>177</td>\n","      <td>80.0</td>\n","      <td>130</td>\n","      <td>80</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>69972</th>\n","      <td>17065</td>\n","      <td>1</td>\n","      <td>165</td>\n","      <td>76.0</td>\n","      <td>140</td>\n","      <td>90</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>69973</th>\n","      <td>22142</td>\n","      <td>2</td>\n","      <td>175</td>\n","      <td>72.0</td>\n","      <td>130</td>\n","      <td>80</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>69974</th>\n","      <td>18226</td>\n","      <td>1</td>\n","      <td>168</td>\n","      <td>75.0</td>\n","      <td>120</td>\n","      <td>80</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>69975</th>\n","      <td>21264</td>\n","      <td>2</td>\n","      <td>182</td>\n","      <td>100.0</td>\n","      <td>120</td>\n","      <td>80</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>69976</th>\n","      <td>21699</td>\n","      <td>1</td>\n","      <td>163</td>\n","      <td>65.0</td>\n","      <td>120</td>\n","      <td>80</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>69977</th>\n","      <td>16843</td>\n","      <td>1</td>\n","      <td>168</td>\n","      <td>75.0</td>\n","      <td>120</td>\n","      <td>79</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>69978</th>\n","      <td>18800</td>\n","      <td>1</td>\n","      <td>163</td>\n","      <td>78.0</td>\n","      <td>90</td>\n","      <td>60</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>69979</th>\n","      <td>22423</td>\n","      <td>1</td>\n","      <td>163</td>\n","      <td>74.0</td>\n","      <td>160</td>\n","      <td>100</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>69980</th>\n","      <td>17727</td>\n","      <td>2</td>\n","      <td>167</td>\n","      <td>69.0</td>\n","      <td>110</td>\n","      <td>80</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>69981</th>\n","      <td>17500</td>\n","      <td>2</td>\n","      <td>182</td>\n","      <td>110.0</td>\n","      <td>130</td>\n","      <td>90</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>69982</th>\n","      <td>18941</td>\n","      <td>1</td>\n","      <td>153</td>\n","      <td>86.0</td>\n","      <td>130</td>\n","      <td>90</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>69983</th>\n","      <td>19652</td>\n","      <td>1</td>\n","      <td>165</td>\n","      <td>72.0</td>\n","      <td>120</td>\n","      <td>80</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>69984</th>\n","      <td>17926</td>\n","      <td>2</td>\n","      <td>168</td>\n","      <td>80.0</td>\n","      <td>120</td>\n","      <td>80</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>69985</th>\n","      <td>18194</td>\n","      <td>1</td>\n","      <td>156</td>\n","      <td>102.0</td>\n","      <td>130</td>\n","      <td>80</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>69986</th>\n","      <td>18198</td>\n","      <td>2</td>\n","      <td>180</td>\n","      <td>78.0</td>\n","      <td>120</td>\n","      <td>80</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>69987</th>\n","      <td>18852</td>\n","      <td>1</td>\n","      <td>151</td>\n","      <td>49.0</td>\n","      <td>120</td>\n","      <td>80</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>69988</th>\n","      <td>21978</td>\n","      <td>1</td>\n","      <td>160</td>\n","      <td>59.0</td>\n","      <td>110</td>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>69989</th>\n","      <td>21013</td>\n","      <td>1</td>\n","      <td>157</td>\n","      <td>83.0</td>\n","      <td>120</td>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>69990</th>\n","      <td>15094</td>\n","      <td>1</td>\n","      <td>168</td>\n","      <td>72.0</td>\n","      <td>110</td>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>69991</th>\n","      <td>20609</td>\n","      <td>1</td>\n","      <td>159</td>\n","      <td>72.0</td>\n","      <td>130</td>\n","      <td>90</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>69992</th>\n","      <td>18792</td>\n","      <td>1</td>\n","      <td>161</td>\n","      <td>56.0</td>\n","      <td>170</td>\n","      <td>90</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>69993</th>\n","      <td>19699</td>\n","      <td>1</td>\n","      <td>172</td>\n","      <td>70.0</td>\n","      <td>130</td>\n","      <td>90</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>69994</th>\n","      <td>21074</td>\n","      <td>1</td>\n","      <td>165</td>\n","      <td>80.0</td>\n","      <td>150</td>\n","      <td>80</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>69995</th>\n","      <td>19240</td>\n","      <td>2</td>\n","      <td>168</td>\n","      <td>76.0</td>\n","      <td>120</td>\n","      <td>80</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>69996</th>\n","      <td>22601</td>\n","      <td>1</td>\n","      <td>158</td>\n","      <td>126.0</td>\n","      <td>140</td>\n","      <td>90</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>69997</th>\n","      <td>19066</td>\n","      <td>2</td>\n","      <td>183</td>\n","      <td>105.0</td>\n","      <td>180</td>\n","      <td>90</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>69998</th>\n","      <td>22431</td>\n","      <td>1</td>\n","      <td>163</td>\n","      <td>72.0</td>\n","      <td>135</td>\n","      <td>80</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>69999</th>\n","      <td>20540</td>\n","      <td>1</td>\n","      <td>170</td>\n","      <td>72.0</td>\n","      <td>120</td>\n","      <td>80</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>70000 rows × 12 columns</p>\n","</div>"],"text/plain":["         age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n","0      18393       2     168    62.0    110     80            1     1      0   \n","1      20228       1     156    85.0    140     90            3     1      0   \n","2      18857       1     165    64.0    130     70            3     1      0   \n","3      17623       2     169    82.0    150    100            1     1      0   \n","4      17474       1     156    56.0    100     60            1     1      0   \n","5      21914       1     151    67.0    120     80            2     2      0   \n","6      22113       1     157    93.0    130     80            3     1      0   \n","7      22584       2     178    95.0    130     90            3     3      0   \n","8      17668       1     158    71.0    110     70            1     1      0   \n","9      19834       1     164    68.0    110     60            1     1      0   \n","10     22530       1     169    80.0    120     80            1     1      0   \n","11     18815       2     173    60.0    120     80            1     1      0   \n","12     14791       2     165    60.0    120     80            1     1      0   \n","13     19809       1     158    78.0    110     70            1     1      0   \n","14     14532       2     181    95.0    130     90            1     1      1   \n","15     16782       2     172   112.0    120     80            1     1      0   \n","16     21296       1     170    75.0    130     70            1     1      0   \n","17     16747       1     158    52.0    110     70            1     3      0   \n","18     17482       1     154    68.0    100     70            1     1      0   \n","19     21755       2     162    56.0    120     70            1     1      1   \n","20     19778       2     163    83.0    120     80            1     1      0   \n","21     21413       1     157    69.0    130     80            1     1      0   \n","22     23046       1     158    90.0    145     85            2     2      0   \n","23     23376       2     156    45.0    110     60            1     1      0   \n","24     16608       1     170    68.0    150     90            3     1      0   \n","25     14453       1     153    65.0    130    100            2     1      0   \n","26     19559       1     156    59.0    130     90            1     1      0   \n","27     18085       1     159    78.0    120     80            1     1      0   \n","28     14574       2     166    66.0    120     80            1     1      0   \n","29     21057       2     169    74.0    130     70            1     3      0   \n","...      ...     ...     ...     ...    ...    ...          ...   ...    ...   \n","69970  22572       2     173   103.0    140     80            3     1      1   \n","69971  20136       2     177    80.0    130     80            1     1      0   \n","69972  17065       1     165    76.0    140     90            1     1      0   \n","69973  22142       2     175    72.0    130     80            1     1      0   \n","69974  18226       1     168    75.0    120     80            1     1      0   \n","69975  21264       2     182   100.0    120     80            1     1      0   \n","69976  21699       1     163    65.0    120     80            2     2      0   \n","69977  16843       1     168    75.0    120     79            1     1      0   \n","69978  18800       1     163    78.0     90     60            1     1      0   \n","69979  22423       1     163    74.0    160    100            2     2      0   \n","69980  17727       2     167    69.0    110     80            1     1      0   \n","69981  17500       2     182   110.0    130     90            2     2      0   \n","69982  18941       1     153    86.0    130     90            1     2      0   \n","69983  19652       1     165    72.0    120     80            1     1      0   \n","69984  17926       2     168    80.0    120     80            1     1      0   \n","69985  18194       1     156   102.0    130     80            1     1      0   \n","69986  18198       2     180    78.0    120     80            1     1      0   \n","69987  18852       1     151    49.0    120     80            1     1      0   \n","69988  21978       1     160    59.0    110     70            1     1      0   \n","69989  21013       1     157    83.0    120     70            1     1      0   \n","69990  15094       1     168    72.0    110     70            1     1      0   \n","69991  20609       1     159    72.0    130     90            2     2      0   \n","69992  18792       1     161    56.0    170     90            1     1      0   \n","69993  19699       1     172    70.0    130     90            1     1      0   \n","69994  21074       1     165    80.0    150     80            1     1      0   \n","69995  19240       2     168    76.0    120     80            1     1      1   \n","69996  22601       1     158   126.0    140     90            2     2      0   \n","69997  19066       2     183   105.0    180     90            3     1      0   \n","69998  22431       1     163    72.0    135     80            1     2      0   \n","69999  20540       1     170    72.0    120     80            2     1      0   \n","\n","       alco  active  cardio  \n","0         0       1       0  \n","1         0       1       1  \n","2         0       0       1  \n","3         0       1       1  \n","4         0       0       0  \n","5         0       0       0  \n","6         0       1       0  \n","7         0       1       1  \n","8         0       1       0  \n","9         0       0       0  \n","10        0       1       0  \n","11        0       1       0  \n","12        0       0       0  \n","13        0       1       0  \n","14        1       1       0  \n","15        0       0       1  \n","16        0       0       0  \n","17        0       1       0  \n","18        0       0       0  \n","19        0       1       0  \n","20        0       1       0  \n","21        0       1       0  \n","22        0       1       1  \n","23        0       1       0  \n","24        0       1       1  \n","25        0       1       0  \n","26        0       1       0  \n","27        0       1       0  \n","28        0       1       0  \n","29        0       0       0  \n","...     ...     ...     ...  \n","69970     1       0       1  \n","69971     0       1       0  \n","69972     0       1       1  \n","69973     0       1       0  \n","69974     0       1       0  \n","69975     0       1       1  \n","69976     0       1       0  \n","69977     0       1       0  \n","69978     0       1       1  \n","69979     0       1       1  \n","69980     1       0       0  \n","69981     0       1       1  \n","69982     0       1       1  \n","69983     0       1       0  \n","69984     0       1       1  \n","69985     1       0       1  \n","69986     0       1       0  \n","69987     0       1       0  \n","69988     0       1       0  \n","69989     0       1       1  \n","69990     0       1       1  \n","69991     0       1       0  \n","69992     0       1       1  \n","69993     0       1       1  \n","69994     0       1       1  \n","69995     0       1       0  \n","69996     0       1       1  \n","69997     1       0       1  \n","69998     0       0       1  \n","69999     0       1       0  \n","\n","[70000 rows x 12 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"xVzf8XbcsGR_","colab_type":"text"},"cell_type":"markdown","source":["# Carga de datos"]},{"metadata":{"ExecuteTime":{"end_time":"2019-03-18T13:28:17.346286Z","start_time":"2019-03-18T13:28:17.247925Z"},"id":"ZdhSC9tPsGSA","colab_type":"code","outputId":"38c8afd4-28c4-4e02-e04d-f186c379201a","executionInfo":{"status":"ok","timestamp":1553290272642,"user_tz":-60,"elapsed":2811,"user":{"displayName":"Francisco del Valle Bas","photoUrl":"","userId":"13762240210727807878"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"cell_type":"code","source":["data = pd.read_csv('cardio_train.csv', sep =';').drop(columns=['id'])\n","\n","#data = data.drop(columns=['Unnamed: 32'])\n","\n","data = pd.get_dummies(data=data, columns=['gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active'])\n","\n","data.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>height</th>\n","      <th>weight</th>\n","      <th>ap_hi</th>\n","      <th>ap_lo</th>\n","      <th>cardio</th>\n","      <th>gender_1</th>\n","      <th>gender_2</th>\n","      <th>cholesterol_1</th>\n","      <th>cholesterol_2</th>\n","      <th>cholesterol_3</th>\n","      <th>gluc_1</th>\n","      <th>gluc_2</th>\n","      <th>gluc_3</th>\n","      <th>smoke_0</th>\n","      <th>smoke_1</th>\n","      <th>alco_0</th>\n","      <th>alco_1</th>\n","      <th>active_0</th>\n","      <th>active_1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>18393</td>\n","      <td>168</td>\n","      <td>62.0</td>\n","      <td>110</td>\n","      <td>80</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>20228</td>\n","      <td>156</td>\n","      <td>85.0</td>\n","      <td>140</td>\n","      <td>90</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>18857</td>\n","      <td>165</td>\n","      <td>64.0</td>\n","      <td>130</td>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>17623</td>\n","      <td>169</td>\n","      <td>82.0</td>\n","      <td>150</td>\n","      <td>100</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>17474</td>\n","      <td>156</td>\n","      <td>56.0</td>\n","      <td>100</td>\n","      <td>60</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     age  height  weight  ap_hi  ap_lo  cardio  gender_1  gender_2  \\\n","0  18393     168    62.0    110     80       0         0         1   \n","1  20228     156    85.0    140     90       1         1         0   \n","2  18857     165    64.0    130     70       1         1         0   \n","3  17623     169    82.0    150    100       1         0         1   \n","4  17474     156    56.0    100     60       0         1         0   \n","\n","   cholesterol_1  cholesterol_2  cholesterol_3  gluc_1  gluc_2  gluc_3  \\\n","0              1              0              0       1       0       0   \n","1              0              0              1       1       0       0   \n","2              0              0              1       1       0       0   \n","3              1              0              0       1       0       0   \n","4              1              0              0       1       0       0   \n","\n","   smoke_0  smoke_1  alco_0  alco_1  active_0  active_1  \n","0        1        0       1       0         0         1  \n","1        1        0       1       0         0         1  \n","2        1        0       1       0         1         0  \n","3        1        0       1       0         0         1  \n","4        1        0       1       0         1         0  "]},"metadata":{"tags":[]},"execution_count":3}]},{"metadata":{"ExecuteTime":{"end_time":"2019-03-18T13:25:10.220065Z","start_time":"2019-03-18T13:25:10.152211Z"},"id":"K4O1sN9RsGSH","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"Eaz_Cmh3sGSJ","colab_type":"text"},"cell_type":"markdown","source":["## Nombre columnas"]},{"metadata":{"ExecuteTime":{"end_time":"2019-03-18T13:28:18.163999Z","start_time":"2019-03-18T13:28:18.159988Z"},"scrolled":true,"id":"JV-rdJCFsGSL","colab_type":"code","outputId":"d19b4c71-f5a1-4a52-9979-67a8726e4874","executionInfo":{"status":"ok","timestamp":1553290272648,"user_tz":-60,"elapsed":2291,"user":{"displayName":"Francisco del Valle Bas","photoUrl":"","userId":"13762240210727807878"}},"colab":{"base_uri":"https://localhost:8080/","height":357}},"cell_type":"code","source":["list(data)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['age',\n"," 'height',\n"," 'weight',\n"," 'ap_hi',\n"," 'ap_lo',\n"," 'cardio',\n"," 'gender_1',\n"," 'gender_2',\n"," 'cholesterol_1',\n"," 'cholesterol_2',\n"," 'cholesterol_3',\n"," 'gluc_1',\n"," 'gluc_2',\n"," 'gluc_3',\n"," 'smoke_0',\n"," 'smoke_1',\n"," 'alco_0',\n"," 'alco_1',\n"," 'active_0',\n"," 'active_1']"]},"metadata":{"tags":[]},"execution_count":4}]},{"metadata":{"id":"is-CEtbVsGSP","colab_type":"text"},"cell_type":"markdown","source":["## Número de columnas"]},{"metadata":{"ExecuteTime":{"end_time":"2019-03-18T13:28:18.666763Z","start_time":"2019-03-18T13:28:18.663780Z"},"id":"8j2n1x2WsGSQ","colab_type":"code","outputId":"40aa4662-00ec-4f34-f083-2da2425923c1","executionInfo":{"status":"ok","timestamp":1553290272650,"user_tz":-60,"elapsed":1949,"user":{"displayName":"Francisco del Valle Bas","photoUrl":"","userId":"13762240210727807878"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["len(list(data))"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["20"]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"KRAiKpT0sGSW","colab_type":"text"},"cell_type":"markdown","source":["## Preparación de los datos"]},{"metadata":{"id":"DIjUrFeBsGSW","colab_type":"text"},"cell_type":"markdown","source":["### Pre-procesamiento "]},{"metadata":{"id":"36M9hXKAsGSa","colab_type":"text"},"cell_type":"markdown","source":["#### Normalización min_max"]},{"metadata":{"ExecuteTime":{"end_time":"2019-03-18T13:28:20.716456Z","start_time":"2019-03-18T13:28:20.695812Z"},"id":"JyVtC-e4sGSc","colab_type":"code","colab":{}},"cell_type":"code","source":["x = data[['age', 'height', 'weight', 'ap_hi', 'ap_lo']].values \n","min_max_scaler = preprocessing.MinMaxScaler()\n","x_scaled = min_max_scaler.fit_transform(x)\n","data[['age', 'height', 'weight', 'ap_hi', 'ap_lo']] = pd.DataFrame(x_scaled, columns = list(data[['age', 'height', 'weight', 'ap_hi', 'ap_lo']]))"],"execution_count":0,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-03-18T13:28:21.083552Z","start_time":"2019-03-18T13:28:21.079518Z"},"id":"Dh10imo5sGSg","colab_type":"code","outputId":"a568e7bb-fa07-454f-f9fe-31cf802833fc","executionInfo":{"status":"ok","timestamp":1553290273374,"user_tz":-60,"elapsed":1675,"user":{"displayName":"Francisco del Valle Bas","photoUrl":"","userId":"13762240210727807878"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["len(data)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["70000"]},"metadata":{"tags":[]},"execution_count":7}]},{"metadata":{"ExecuteTime":{"end_time":"2019-03-07T11:27:23.619792Z","start_time":"2019-03-07T11:27:23.616826Z"},"id":"1iJWDPETsGSk","colab_type":"text"},"cell_type":"markdown","source":["### Definición de X e y"]},{"metadata":{"ExecuteTime":{"end_time":"2019-03-18T13:28:21.616799Z","start_time":"2019-03-18T13:28:21.600733Z"},"id":"nSY3L7DdsGSl","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","# Todos los valores menos el valor a predecir\n","X = data.drop(columns=['cardio']).values\n","\n","\n","y = data.cardio.astype('category').cat.codes.values.reshape((np.shape(X)[0], 1))\n","\n","\n","y = to_categorical(y)\n","\n","# Target o valor a predecir\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"he77fkyG4inx","colab_type":"code","colab":{}},"cell_type":"code","source":["y = data['cardio']"],"execution_count":0,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-03-11T13:55:49.768225Z","start_time":"2019-03-11T13:55:49.763197Z"},"id":"YfLjzpk6sGSq","colab_type":"code","outputId":"eb55ec40-eaa5-4d0f-f7d1-5247116e6548","executionInfo":{"status":"ok","timestamp":1553290274178,"user_tz":-60,"elapsed":1610,"user":{"displayName":"Francisco del Valle Bas","photoUrl":"","userId":"13762240210727807878"}},"colab":{"base_uri":"https://localhost:8080/","height":1071}},"cell_type":"code","source":["y"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0        0\n","1        1\n","2        1\n","3        1\n","4        0\n","5        0\n","6        0\n","7        1\n","8        0\n","9        0\n","10       0\n","11       0\n","12       0\n","13       0\n","14       0\n","15       1\n","16       0\n","17       0\n","18       0\n","19       0\n","20       0\n","21       0\n","22       1\n","23       0\n","24       1\n","25       0\n","26       0\n","27       0\n","28       0\n","29       0\n","        ..\n","69970    1\n","69971    0\n","69972    1\n","69973    0\n","69974    0\n","69975    1\n","69976    0\n","69977    0\n","69978    1\n","69979    1\n","69980    0\n","69981    1\n","69982    1\n","69983    0\n","69984    1\n","69985    1\n","69986    0\n","69987    0\n","69988    0\n","69989    1\n","69990    1\n","69991    0\n","69992    1\n","69993    1\n","69994    1\n","69995    0\n","69996    1\n","69997    1\n","69998    1\n","69999    0\n","Name: cardio, Length: 70000, dtype: int64"]},"metadata":{"tags":[]},"execution_count":10}]},{"metadata":{"ExecuteTime":{"end_time":"2019-03-18T13:28:23.206689Z","start_time":"2019-03-18T13:28:23.182488Z"},"id":"tWZZF9TdsGSu","colab_type":"code","colab":{}},"cell_type":"code","source":["# Separación de los datos\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify = y)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Tisypaprysl9","colab_type":"code","outputId":"2eee80f0-f657-4fde-ac94-a56d125106ca","executionInfo":{"status":"ok","timestamp":1553290274183,"user_tz":-60,"elapsed":1255,"user":{"displayName":"Francisco del Valle Bas","photoUrl":"","userId":"13762240210727807878"}},"colab":{"base_uri":"https://localhost:8080/","height":1071}},"cell_type":"code","source":["y_test"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["18682    0\n","40992    0\n","38068    0\n","12096    1\n","17791    1\n","67778    0\n","58068    1\n","25898    0\n","32489    0\n","24734    1\n","228      1\n","64514    1\n","56378    0\n","11179    0\n","16551    0\n","29848    1\n","24552    1\n","50171    0\n","3759     1\n","54879    1\n","67707    1\n","67702    1\n","58491    1\n","53401    1\n","50070    1\n","4869     0\n","54614    1\n","53203    1\n","24817    1\n","46340    1\n","        ..\n","52919    0\n","31247    1\n","43028    1\n","1429     1\n","55855    0\n","21942    1\n","53723    1\n","20610    1\n","37106    1\n","14989    1\n","27145    0\n","12429    1\n","13378    1\n","24261    1\n","55962    0\n","61861    1\n","7503     1\n","20883    1\n","46003    1\n","41505    0\n","57571    1\n","63511    0\n","1174     1\n","37118    0\n","31870    1\n","24109    0\n","28664    1\n","58670    0\n","7760     1\n","18396    1\n","Name: cardio, Length: 14000, dtype: int64"]},"metadata":{"tags":[]},"execution_count":12}]},{"metadata":{"id":"mE21ReAzzfzr","colab_type":"code","colab":{}},"cell_type":"code","source":["X_conv_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n","X_conv_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"],"execution_count":0,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-03-18T13:28:24.722998Z","start_time":"2019-03-18T13:28:24.719988Z"},"id":"4ixv0w5rsGS0","colab_type":"code","outputId":"11ab7b48-8323-4f3c-c0a1-48b7fb8ccea9","executionInfo":{"status":"ok","timestamp":1553290274940,"user_tz":-60,"elapsed":1692,"user":{"displayName":"Francisco del Valle Bas","photoUrl":"","userId":"13762240210727807878"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["X_conv_train.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(56000, 19, 1)"]},"metadata":{"tags":[]},"execution_count":14}]},{"metadata":{"id":"Dm-IUVemsGS8","colab_type":"text"},"cell_type":"markdown","source":["# Definición del modelo"]},{"metadata":{"ExecuteTime":{"end_time":"2019-03-18T13:28:41.666553Z","start_time":"2019-03-18T13:28:41.663541Z"},"id":"ta4UlpcVsGS-","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D, GlobalMaxPooling1D"],"execution_count":0,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-03-18T13:28:41.918091Z","start_time":"2019-03-18T13:28:41.911096Z"},"id":"ZQKobUDcsGTB","colab_type":"code","colab":{}},"cell_type":"code","source":["def conv1d_model(num_features):\n","\n","    model_m = Sequential()\n","    \n","    model_m.add(Conv1D(250, kernel_size= 3, activation='relu', input_shape=(19, 1)))\n","    \n","    \n","    \n","    model_m.add(MaxPooling1D(2))\n","    \n","    model_m.add(Conv1D(320, kernel_size = 3, activation='relu'))\n","    \n","    model_m.add(GlobalMaxPooling1D())\n","  \n","    model_m.add(Dropout(0.2))\n","    \n","    model_m.add(Dense(512, activation='relu'))\n","    \n","    model_m.add(Dense(256, activation='relu'))\n","    \n","    #model_m.add(Flatten())\n","    \n","    model_m.add(Dense(1,activation='sigmoid'))\n","    \n","    #adam= Adam(lr=0.01)\n","    \n","    model_m.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    \n","    return model_m"],"execution_count":0,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-03-18T13:28:42.323804Z","start_time":"2019-03-18T13:28:42.150967Z"},"id":"ekvPthnfsGTD","colab_type":"code","outputId":"0d747485-a062-44f7-a451-94e1cb8728eb","executionInfo":{"status":"ok","timestamp":1553290275595,"user_tz":-60,"elapsed":1207,"user":{"displayName":"Francisco del Valle Bas","photoUrl":"","userId":"13762240210727807878"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"cell_type":"code","source":["model_m = conv1d_model(11)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"}]},{"metadata":{"id":"9j4rWg5Y75Sf","colab_type":"code","outputId":"8eb17bf7-17e5-48a3-e9b0-039a21a09d5c","colab":{"base_uri":"https://localhost:8080/","height":2026}},"cell_type":"code","source":["history_conv = model_m.fit(X_conv_train, y_train, validation_data=(X_conv_test, y_test), epochs=1000, verbose=1, batch_size=200)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","Train on 56000 samples, validate on 14000 samples\n","Epoch 1/1000\n","56000/56000 [==============================] - 5s 89us/step - loss: 0.6485 - acc: 0.6157 - val_loss: 0.6374 - val_acc: 0.6379\n","Epoch 2/1000\n","56000/56000 [==============================] - 3s 56us/step - loss: 0.6348 - acc: 0.6382 - val_loss: 0.6385 - val_acc: 0.6345\n","Epoch 3/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.6314 - acc: 0.6435 - val_loss: 0.6339 - val_acc: 0.6411\n","Epoch 4/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.6302 - acc: 0.6430 - val_loss: 0.6326 - val_acc: 0.6423\n","Epoch 5/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.6296 - acc: 0.6439 - val_loss: 0.6297 - val_acc: 0.6479\n","Epoch 6/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.6280 - acc: 0.6455 - val_loss: 0.6299 - val_acc: 0.6459\n","Epoch 7/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.6256 - acc: 0.6484 - val_loss: 0.6299 - val_acc: 0.6445\n","Epoch 8/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.6271 - acc: 0.6472 - val_loss: 0.6249 - val_acc: 0.6495\n","Epoch 9/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.6239 - acc: 0.6511 - val_loss: 0.6245 - val_acc: 0.6469\n","Epoch 10/1000\n","56000/56000 [==============================] - 3s 54us/step - loss: 0.6221 - acc: 0.6527 - val_loss: 0.6261 - val_acc: 0.6520\n","Epoch 11/1000\n","56000/56000 [==============================] - 3s 54us/step - loss: 0.6159 - acc: 0.6596 - val_loss: 0.6144 - val_acc: 0.6598\n","Epoch 12/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.6049 - acc: 0.6731 - val_loss: 0.5875 - val_acc: 0.6930\n","Epoch 13/1000\n","56000/56000 [==============================] - 3s 56us/step - loss: 0.5818 - acc: 0.6989 - val_loss: 0.6069 - val_acc: 0.6675\n","Epoch 14/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.5747 - acc: 0.7066 - val_loss: 0.5900 - val_acc: 0.6825\n","Epoch 15/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.5672 - acc: 0.7132 - val_loss: 0.5790 - val_acc: 0.6956\n","Epoch 16/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.5597 - acc: 0.7216 - val_loss: 0.5536 - val_acc: 0.7244\n","Epoch 17/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.5583 - acc: 0.7222 - val_loss: 0.5533 - val_acc: 0.7240\n","Epoch 18/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.5637 - acc: 0.7144 - val_loss: 0.5891 - val_acc: 0.6891\n","Epoch 19/1000\n","56000/56000 [==============================] - 3s 54us/step - loss: 0.5623 - acc: 0.7177 - val_loss: 0.5610 - val_acc: 0.7205\n","Epoch 20/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.5540 - acc: 0.7264 - val_loss: 0.5531 - val_acc: 0.7279\n","Epoch 21/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.5557 - acc: 0.7244 - val_loss: 0.5548 - val_acc: 0.7253\n","Epoch 22/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.5595 - acc: 0.7205 - val_loss: 0.5686 - val_acc: 0.7151\n","Epoch 23/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.5579 - acc: 0.7228 - val_loss: 0.5506 - val_acc: 0.7295\n","Epoch 24/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.5519 - acc: 0.7270 - val_loss: 0.5715 - val_acc: 0.7089\n","Epoch 25/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.5544 - acc: 0.7255 - val_loss: 0.5498 - val_acc: 0.7291\n","Epoch 26/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.5524 - acc: 0.7293 - val_loss: 0.5635 - val_acc: 0.7160\n","Epoch 27/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.5526 - acc: 0.7279 - val_loss: 0.5502 - val_acc: 0.7314\n","Epoch 28/1000\n","56000/56000 [==============================] - 3s 56us/step - loss: 0.5527 - acc: 0.7276 - val_loss: 0.5509 - val_acc: 0.7273\n","Epoch 29/1000\n","56000/56000 [==============================] - 3s 54us/step - loss: 0.5511 - acc: 0.7284 - val_loss: 0.5527 - val_acc: 0.7276\n","Epoch 30/1000\n","56000/56000 [==============================] - 3s 54us/step - loss: 0.5530 - acc: 0.7258 - val_loss: 0.5615 - val_acc: 0.7235\n","Epoch 31/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.5519 - acc: 0.7265 - val_loss: 0.5496 - val_acc: 0.7306\n","Epoch 32/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.5537 - acc: 0.7277 - val_loss: 0.5512 - val_acc: 0.7267\n","Epoch 33/1000\n","56000/56000 [==============================] - 3s 54us/step - loss: 0.5508 - acc: 0.7283 - val_loss: 0.5511 - val_acc: 0.7274\n","Epoch 34/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.5526 - acc: 0.7268 - val_loss: 0.5544 - val_acc: 0.7240\n","Epoch 35/1000\n","56000/56000 [==============================] - 3s 56us/step - loss: 0.5509 - acc: 0.7298 - val_loss: 0.5662 - val_acc: 0.7138\n","Epoch 36/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.5510 - acc: 0.7273 - val_loss: 0.5490 - val_acc: 0.7281\n","Epoch 37/1000\n","56000/56000 [==============================] - 3s 54us/step - loss: 0.5529 - acc: 0.7263 - val_loss: 0.5556 - val_acc: 0.7255\n","Epoch 38/1000\n","56000/56000 [==============================] - 3s 57us/step - loss: 0.5510 - acc: 0.7286 - val_loss: 0.5537 - val_acc: 0.7264\n","Epoch 39/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.5505 - acc: 0.7290 - val_loss: 0.5685 - val_acc: 0.7085\n","Epoch 40/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.5525 - acc: 0.7260 - val_loss: 0.5870 - val_acc: 0.6804\n","Epoch 41/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.5500 - acc: 0.7297 - val_loss: 0.5579 - val_acc: 0.7251\n","Epoch 42/1000\n","56000/56000 [==============================] - 3s 56us/step - loss: 0.5549 - acc: 0.7253 - val_loss: 0.5588 - val_acc: 0.7202\n","Epoch 43/1000\n","56000/56000 [==============================] - 3s 60us/step - loss: 0.5499 - acc: 0.7303 - val_loss: 0.5550 - val_acc: 0.7254\n","Epoch 44/1000\n","56000/56000 [==============================] - 3s 59us/step - loss: 0.5509 - acc: 0.7280 - val_loss: 0.5606 - val_acc: 0.7166\n","Epoch 45/1000\n","56000/56000 [==============================] - 3s 56us/step - loss: 0.5495 - acc: 0.7298 - val_loss: 0.5529 - val_acc: 0.7268\n","Epoch 46/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.5515 - acc: 0.7273 - val_loss: 0.5596 - val_acc: 0.7190\n","Epoch 47/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.5517 - acc: 0.7276 - val_loss: 0.5481 - val_acc: 0.7311\n","Epoch 48/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.5504 - acc: 0.7279 - val_loss: 0.5498 - val_acc: 0.7296\n","Epoch 49/1000\n","56000/56000 [==============================] - 3s 55us/step - loss: 0.5506 - acc: 0.7281 - val_loss: 0.5499 - val_acc: 0.7284\n","Epoch 50/1000\n","56000/56000 [==============================] - 3s 58us/step - loss: 0.5493 - acc: 0.7284 - val_loss: 0.5536 - val_acc: 0.7264\n","Epoch 51/1000\n","56000/56000 [==============================] - 4s 66us/step - loss: 0.5507 - acc: 0.7281 - val_loss: 0.5576 - val_acc: 0.7229\n","Epoch 52/1000\n","56000/56000 [==============================] - 6s 112us/step - loss: 0.5500 - acc: 0.7298 - val_loss: 0.5489 - val_acc: 0.7319\n","Epoch 53/1000\n","56000/56000 [==============================] - 8s 137us/step - loss: 0.5519 - acc: 0.7268 - val_loss: 0.5630 - val_acc: 0.7188\n","Epoch 54/1000\n","56000/56000 [==============================] - 7s 133us/step - loss: 0.5466 - acc: 0.7324 - val_loss: 0.5483 - val_acc: 0.7329\n","Epoch 55/1000\n","20800/56000 [==========>...................] - ETA: 4s - loss: 0.5480 - acc: 0.7316"],"name":"stdout"}]},{"metadata":{"id":"B9zxyvkb5zDK","colab_type":"code","outputId":"f5a1b196-cf34-4b15-fb50-b14e98d94cd1","executionInfo":{"status":"error","timestamp":1553269424127,"user_tz":-60,"elapsed":2038,"user":{"displayName":"juan serrano","photoUrl":"","userId":"03763373986234517743"}},"colab":{"base_uri":"https://localhost:8080/","height":164}},"cell_type":"code","source":["print(model_m.summary())"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-9d2a0919fe83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model_m' is not defined"]}]},{"metadata":{"id":"GXO08Og5Bpie","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.plot(history_conv.history['loss'], label = 'loss') \n","plt.plot(history_conv.history['val_loss'], label = 'val_loss') \n","plt.legend()\n","plt.show()\n","\n","\n","plt.plot(history_conv.history['acc'], label = 'acc') \n","plt.plot(history_conv.history['val_acc'], label = 'val_acc') \n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AahupOLhsGTH","colab_type":"text"},"cell_type":"markdown","source":["## Entrenamiento del modelo"]},{"metadata":{"id":"t_-3OrV4sGTH","colab_type":"text"},"cell_type":"markdown","source":["### Learning rate schedule"]},{"metadata":{"ExecuteTime":{"end_time":"2019-03-18T13:28:43.233758Z","start_time":"2019-03-18T13:28:43.229723Z"},"id":"sc7NwI_WsGTI","colab_type":"code","outputId":"1ca86224-a7ee-43a1-fbb8-92a5ec9c5b98","executionInfo":{"status":"error","timestamp":1553269424568,"user_tz":-60,"elapsed":1324,"user":{"displayName":"juan serrano","photoUrl":"","userId":"03763373986234517743"}},"colab":{"base_uri":"https://localhost:8080/","height":184}},"cell_type":"code","source":["rlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=40, min_delta=1E-7, verbose=1)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-bc5b4b9be1de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrlrp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1E-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'ReduceLROnPlateau' is not defined"]}]},{"metadata":{"id":"aYfx4RMlsGTK","colab_type":"text"},"cell_type":"markdown","source":["### Early Stopping"]},{"metadata":{"ExecuteTime":{"end_time":"2019-03-18T13:28:44.041922Z","start_time":"2019-03-18T13:28:44.038889Z"},"id":"QWHWXGnbsGTL","colab_type":"code","outputId":"9e725107-7ed6-4617-8b65-a1649f8a94e9","executionInfo":{"status":"error","timestamp":1553269424570,"user_tz":-60,"elapsed":794,"user":{"displayName":"juan serrano","photoUrl":"","userId":"03763373986234517743"}},"colab":{"base_uri":"https://localhost:8080/","height":164}},"cell_type":"code","source":["es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-7defc4c2ebba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'EarlyStopping' is not defined"]}]},{"metadata":{"ExecuteTime":{"start_time":"2019-03-18T13:28:44.654Z"},"id":"24XWt2dKsGTO","colab_type":"code","outputId":"9fe782ef-3bfa-493b-daff-fcdef7cb948a","executionInfo":{"status":"error","timestamp":1553269425596,"user_tz":-60,"elapsed":1536,"user":{"displayName":"juan serrano","photoUrl":"","userId":"03763373986234517743"}},"colab":{"base_uri":"https://localhost:8080/","height":184}},"cell_type":"code","source":["history_conv = model_m.fit(X_conv_train, y_train, validation_data=(X_conv_test, y_test), epochs=1000, verbose=1, batch_size=200)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-6c067a416cc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory_conv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_conv_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_conv_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model_m' is not defined"]}]},{"metadata":{"id":"zFh2V8zEsGTR","colab_type":"text"},"cell_type":"markdown","source":["### Model fit"]},{"metadata":{"id":"Ptz6gEXcsGTR","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-03-12T09:55:47.754265Z","start_time":"2019-03-12T09:55:47.623170Z"},"id":"54-IviKBsGTU","colab_type":"code","outputId":"362307ff-bd28-4532-fff9-6669e0161eeb","executionInfo":{"status":"error","timestamp":1553269426695,"user_tz":-60,"elapsed":904,"user":{"displayName":"juan serrano","photoUrl":"","userId":"03763373986234517743"}},"colab":{"base_uri":"https://localhost:8080/","height":252}},"cell_type":"code","source":["model = Sequential()\n","\n","model.add(Dense(64, input_dim=X_train.shape[1], activation ='selu', kernel_regularizer=l2(0.01)))\n","\n","model.add(Dropout(0.1))\n","#model.add(BatchNormalization())\n","\n","model.add(Dense(64, input_dim=X_train.shape[1], activation ='selu', kernel_regularizer=l2(0.01)))\n","\n","\n","\n","model.add(Dense(2))\n","\n","opt = SGD(lr=0.01, momentum=0.9)\n","\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-3bc39ca98a37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'selu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"]}]},{"metadata":{"id":"gvb-P_2HsGTW","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-03-12T09:51:47.471666Z","start_time":"2019-03-12T09:47:49.911061Z"},"id":"mGY4wVWasGTY","colab_type":"code","outputId":"054962d0-bc04-4350-f2f7-5b5a0cca07e5","executionInfo":{"status":"error","timestamp":1553269427901,"user_tz":-60,"elapsed":1539,"user":{"displayName":"juan serrano","photoUrl":"","userId":"03763373986234517743"}},"colab":{"base_uri":"https://localhost:8080/","height":184}},"cell_type":"code","source":["history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1000000, verbose=1, callbacks=[rlrp, es], batch_size=100)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-2136c3bb724e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrlrp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"metadata":{"ExecuteTime":{"end_time":"2019-03-05T16:27:26.772199Z","start_time":"2019-03-05T16:27:26.768230Z"},"id":"eVQ637qOsGTd","colab_type":"text"},"cell_type":"markdown","source":["# Model Evaluation"]},{"metadata":{"ExecuteTime":{"end_time":"2019-03-12T09:51:49.548665Z","start_time":"2019-03-12T09:51:47.472667Z"},"id":"zy8AC7l-sGTe","colab_type":"code","outputId":"c93c5f95-de73-47f3-a999-3437bba439d2","executionInfo":{"status":"error","timestamp":1553269427902,"user_tz":-60,"elapsed":908,"user":{"displayName":"juan serrano","photoUrl":"","userId":"03763373986234517743"}},"colab":{"base_uri":"https://localhost:8080/","height":232}},"cell_type":"code","source":["# evaluate the model\n","_, train_acc = model.evaluate(X_train, y_train, verbose=0)\n","_, test_acc = model.evaluate(X_test, y_test, verbose=0)\n","print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n","# plot loss learning curves\n","pyplot.subplot(211)\n","pyplot.title('Cross-Entropy Loss', pad=-40)\n","pyplot.plot(history.history['loss'], label='train')\n","pyplot.plot(history.history['val_loss'], label='test')\n","pyplot.legend()\n","# plot accuracy learning curves\n","pyplot.subplot(212)\n","pyplot.title('Accuracy', pad=-40)\n","pyplot.plot(history.history['acc'], label='train')\n","pyplot.plot(history.history['val_acc'], label='test')\n","pyplot.legend()\n","pyplot.show()"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-26c2389b7342>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train: %.3f, Test: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# plot loss learning curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m211\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"metadata":{"id":"U53XinF4sGTh","colab_type":"code","outputId":"49a9e574-c58f-4493-afd3-a13b9704e8fd","executionInfo":{"status":"ok","timestamp":1553306907189,"user_tz":-60,"elapsed":777,"user":{"displayName":"Francisco del Valle Bas","photoUrl":"","userId":"13762240210727807878"}},"colab":{"base_uri":"https://localhost:8080/","height":2006}},"cell_type":"code","source":["\n","data = pd.read_csv('data.csv', sep =',')\n","data = data.drop(columns = ['slope','ca','thal'])\n","data.columns = ['age',\n","                'sex',\n","                'cp',\n","                'trestbps',\n","                'chol',\n","                'fbs',\n","                'restecg',\n","                'thalach',\n","                'exang',\n","                'oldpeak', \n","                'num']\n","\n","for col in data.columns.values:\n","\n","  if('?' in data[col].values):\n","  \n","    \n","    data = data[data[col] != '?']\n","data"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>cp</th>\n","      <th>trestbps</th>\n","      <th>chol</th>\n","      <th>fbs</th>\n","      <th>restecg</th>\n","      <th>thalach</th>\n","      <th>exang</th>\n","      <th>oldpeak</th>\n","      <th>num</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>28</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>130</td>\n","      <td>132</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>185</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>29</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>120</td>\n","      <td>243</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>160</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>30</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>170</td>\n","      <td>237</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>170</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>31</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>100</td>\n","      <td>219</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>150</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>32</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>105</td>\n","      <td>198</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>165</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>32</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>110</td>\n","      <td>225</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>184</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>32</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>125</td>\n","      <td>254</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>155</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>33</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>120</td>\n","      <td>298</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>185</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>34</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>130</td>\n","      <td>161</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>190</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>34</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>150</td>\n","      <td>214</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>168</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>34</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>98</td>\n","      <td>220</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>150</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>35</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>120</td>\n","      <td>160</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>185</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>35</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>140</td>\n","      <td>167</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>150</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>35</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>120</td>\n","      <td>308</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>180</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>35</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>150</td>\n","      <td>264</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>168</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>36</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>120</td>\n","      <td>166</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>180</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>36</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>112</td>\n","      <td>340</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>184</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>36</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>130</td>\n","      <td>209</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>178</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>36</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>150</td>\n","      <td>160</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>172</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>37</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>120</td>\n","      <td>260</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>130</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>37</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>130</td>\n","      <td>211</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>142</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>37</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>130</td>\n","      <td>173</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>184</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>37</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>130</td>\n","      <td>283</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>98</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>37</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>130</td>\n","      <td>194</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>150</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>37</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>120</td>\n","      <td>223</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>168</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>37</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>130</td>\n","      <td>315</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>158</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>38</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>140</td>\n","      <td>297</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>150</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>38</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>145</td>\n","      <td>292</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>130</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>39</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>110</td>\n","      <td>182</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>180</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>39</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>120</td>\n","      <td>200</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>160</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>261</th>\n","      <td>52</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>112</td>\n","      <td>342</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>96</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>262</th>\n","      <td>52</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>130</td>\n","      <td>298</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>110</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>263</th>\n","      <td>52</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>140</td>\n","      <td>404</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>124</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>264</th>\n","      <td>52</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>160</td>\n","      <td>246</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>82</td>\n","      <td>1</td>\n","      <td>4.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>265</th>\n","      <td>53</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>145</td>\n","      <td>518</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>130</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>266</th>\n","      <td>53</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>180</td>\n","      <td>285</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>120</td>\n","      <td>1</td>\n","      <td>1.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>267</th>\n","      <td>54</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>140</td>\n","      <td>216</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>105</td>\n","      <td>0</td>\n","      <td>1.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>269</th>\n","      <td>55</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>160</td>\n","      <td>292</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>143</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>270</th>\n","      <td>55</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>145</td>\n","      <td>248</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>96</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>271</th>\n","      <td>56</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>120</td>\n","      <td>279</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>150</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>272</th>\n","      <td>56</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>150</td>\n","      <td>230</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>124</td>\n","      <td>1</td>\n","      <td>1.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>273</th>\n","      <td>56</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>170</td>\n","      <td>388</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>122</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>274</th>\n","      <td>58</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>136</td>\n","      <td>164</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>99</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>276</th>\n","      <td>59</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>140</td>\n","      <td>264</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>119</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>277</th>\n","      <td>65</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>170</td>\n","      <td>263</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>112</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>279</th>\n","      <td>41</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>120</td>\n","      <td>336</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>118</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>280</th>\n","      <td>43</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>140</td>\n","      <td>288</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>135</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>281</th>\n","      <td>44</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>135</td>\n","      <td>491</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>135</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>282</th>\n","      <td>47</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>120</td>\n","      <td>205</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>98</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>283</th>\n","      <td>47</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>160</td>\n","      <td>291</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>158</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>284</th>\n","      <td>49</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>128</td>\n","      <td>212</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>96</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>285</th>\n","      <td>49</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>150</td>\n","      <td>222</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>122</td>\n","      <td>0</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>286</th>\n","      <td>50</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>140</td>\n","      <td>231</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>140</td>\n","      <td>1</td>\n","      <td>5.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>287</th>\n","      <td>50</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>140</td>\n","      <td>341</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>125</td>\n","      <td>1</td>\n","      <td>2.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>288</th>\n","      <td>52</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>140</td>\n","      <td>266</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>134</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>289</th>\n","      <td>52</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>160</td>\n","      <td>331</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>94</td>\n","      <td>1</td>\n","      <td>2.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>290</th>\n","      <td>54</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>130</td>\n","      <td>294</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>100</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>291</th>\n","      <td>56</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>155</td>\n","      <td>342</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>150</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>292</th>\n","      <td>58</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>180</td>\n","      <td>393</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>110</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>293</th>\n","      <td>65</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>130</td>\n","      <td>275</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>115</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>261 rows × 11 columns</p>\n","</div>"],"text/plain":["     age  sex  cp trestbps chol fbs restecg thalach exang  oldpeak  num\n","0     28    1   2      130  132   0       2     185     0      0.0    0\n","1     29    1   2      120  243   0       0     160     0      0.0    0\n","3     30    0   1      170  237   0       1     170     0      0.0    0\n","4     31    0   2      100  219   0       1     150     0      0.0    0\n","5     32    0   2      105  198   0       0     165     0      0.0    0\n","6     32    1   2      110  225   0       0     184     0      0.0    0\n","7     32    1   2      125  254   0       0     155     0      0.0    0\n","8     33    1   3      120  298   0       0     185     0      0.0    0\n","9     34    0   2      130  161   0       0     190     0      0.0    0\n","10    34    1   2      150  214   0       1     168     0      0.0    0\n","11    34    1   2       98  220   0       0     150     0      0.0    0\n","12    35    0   1      120  160   0       1     185     0      0.0    0\n","13    35    0   4      140  167   0       0     150     0      0.0    0\n","14    35    1   2      120  308   0       2     180     0      0.0    0\n","15    35    1   2      150  264   0       0     168     0      0.0    0\n","16    36    1   2      120  166   0       0     180     0      0.0    0\n","17    36    1   3      112  340   0       0     184     0      1.0    0\n","18    36    1   3      130  209   0       0     178     0      0.0    0\n","19    36    1   3      150  160   0       0     172     0      0.0    0\n","20    37    0   2      120  260   0       0     130     0      0.0    0\n","21    37    0   3      130  211   0       0     142     0      0.0    0\n","22    37    0   4      130  173   0       1     184     0      0.0    0\n","23    37    1   2      130  283   0       1      98     0      0.0    0\n","24    37    1   3      130  194   0       0     150     0      0.0    0\n","25    37    1   4      120  223   0       0     168     0      0.0    0\n","26    37    1   4      130  315   0       0     158     0      0.0    0\n","28    38    1   2      140  297   0       0     150     0      0.0    0\n","29    38    1   3      145  292   0       0     130     0      0.0    0\n","30    39    0   3      110  182   0       1     180     0      0.0    0\n","32    39    1   2      120  200   0       0     160     1      1.0    0\n","..   ...  ...  ..      ...  ...  ..     ...     ...   ...      ...  ...\n","261   52    1   4      112  342   0       1      96     1      1.0    1\n","262   52    1   4      130  298   0       0     110     1      1.0    1\n","263   52    1   4      140  404   0       0     124     1      2.0    1\n","264   52    1   4      160  246   0       1      82     1      4.0    1\n","265   53    1   3      145  518   0       0     130     0      0.0    1\n","266   53    1   4      180  285   0       1     120     1      1.5    1\n","267   54    1   4      140  216   0       0     105     0      1.5    1\n","269   55    1   2      160  292   1       0     143     1      2.0    1\n","270   55    1   4      145  248   0       0      96     1      2.0    1\n","271   56    0   2      120  279   0       0     150     0      1.0    1\n","272   56    1   4      150  230   0       1     124     1      1.5    1\n","273   56    1   4      170  388   0       1     122     1      2.0    1\n","274   58    1   2      136  164   0       1      99     1      2.0    1\n","276   59    1   4      140  264   1       2     119     1      0.0    1\n","277   65    1   4      170  263   1       0     112     1      2.0    1\n","279   41    1   4      120  336   0       0     118     1      3.0    1\n","280   43    1   4      140  288   0       0     135     1      2.0    1\n","281   44    1   4      135  491   0       0     135     0      0.0    1\n","282   47    0   4      120  205   0       0      98     1      2.0    1\n","283   47    1   4      160  291   0       1     158     1      3.0    1\n","284   49    1   4      128  212   0       0      96     1      0.0    1\n","285   49    1   4      150  222   0       0     122     0      2.0    1\n","286   50    1   4      140  231   0       1     140     1      5.0    1\n","287   50    1   4      140  341   0       1     125     1      2.5    1\n","288   52    1   4      140  266   0       0     134     1      2.0    1\n","289   52    1   4      160  331   0       0      94     1      2.5    1\n","290   54    0   3      130  294   0       1     100     1      0.0    1\n","291   56    1   4      155  342   1       0     150     1      3.0    1\n","292   58    0   2      180  393   0       0     110     1      1.0    1\n","293   65    1   4      130  275   0       1     115     1      1.0    1\n","\n","[261 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"metadata":{"id":"JUo07SxEwFPF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":224},"outputId":"b8805895-fc87-4031-ccb9-184286f16fdd","executionInfo":{"status":"ok","timestamp":1553306910277,"user_tz":-60,"elapsed":671,"user":{"displayName":"Francisco del Valle Bas","photoUrl":"","userId":"13762240210727807878"}}},"cell_type":"code","source":["data = pd.get_dummies(data=data, columns=['cp', 'exang','fbs','restecg'])\n","\n","data.head()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>trestbps</th>\n","      <th>chol</th>\n","      <th>thalach</th>\n","      <th>oldpeak</th>\n","      <th>num</th>\n","      <th>cp_1</th>\n","      <th>cp_2</th>\n","      <th>cp_3</th>\n","      <th>cp_4</th>\n","      <th>exang_0</th>\n","      <th>exang_1</th>\n","      <th>fbs_0</th>\n","      <th>fbs_1</th>\n","      <th>restecg_0</th>\n","      <th>restecg_1</th>\n","      <th>restecg_2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>28</td>\n","      <td>1</td>\n","      <td>130</td>\n","      <td>132</td>\n","      <td>185</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>29</td>\n","      <td>1</td>\n","      <td>120</td>\n","      <td>243</td>\n","      <td>160</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>30</td>\n","      <td>0</td>\n","      <td>170</td>\n","      <td>237</td>\n","      <td>170</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>31</td>\n","      <td>0</td>\n","      <td>100</td>\n","      <td>219</td>\n","      <td>150</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>32</td>\n","      <td>0</td>\n","      <td>105</td>\n","      <td>198</td>\n","      <td>165</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   age  sex trestbps chol thalach  oldpeak  num  cp_1  cp_2  cp_3  cp_4  \\\n","0   28    1      130  132     185      0.0    0     0     1     0     0   \n","1   29    1      120  243     160      0.0    0     0     1     0     0   \n","3   30    0      170  237     170      0.0    0     1     0     0     0   \n","4   31    0      100  219     150      0.0    0     0     1     0     0   \n","5   32    0      105  198     165      0.0    0     0     1     0     0   \n","\n","   exang_0  exang_1  fbs_0  fbs_1  restecg_0  restecg_1  restecg_2  \n","0        1        0      1      0          0          0          1  \n","1        1        0      1      0          1          0          0  \n","3        1        0      1      0          0          1          0  \n","4        1        0      1      0          0          1          0  \n","5        1        0      1      0          1          0          0  "]},"metadata":{"tags":[]},"execution_count":8}]},{"metadata":{"id":"h1fbJVlWsGTi","colab_type":"code","colab":{}},"cell_type":"code","source":["X = data.drop(columns = ['num']).values\n","y = data['num'].values"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oJsWXy3Ht9tf","colab_type":"code","colab":{}},"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify = y)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"x4nIrQx-uwsY","colab_type":"code","outputId":"080cf1be-fd26-43aa-fc04-c304e1316c58","executionInfo":{"status":"error","timestamp":1553272604508,"user_tz":-60,"elapsed":736,"user":{"displayName":"juan serrano","photoUrl":"","userId":"03763373986234517743"}},"colab":{"base_uri":"https://localhost:8080/","height":198}},"cell_type":"code","source":["X_conv_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n","X_conv_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n","X_conv_train.shape"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-dad9a7882201>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_conv_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_conv_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_conv_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"]}]},{"metadata":{"id":"-lmVNFVSvX_-","colab_type":"code","colab":{}},"cell_type":"code","source":["def conv1d_model(num_features):\n","\n","    model_m = Sequential()\n","    model_m.add(Dense(512, activation='relu',input_shape=(17,)))\n","    model_m.add(Dense(256, activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n","    \n","    model_m.add(Dense(1,activation='sigmoid'))\n","    \n","    adam= Adam(lr=0.0001)\n","    \n","    model_m.compile(loss='binary_crossentropy', optimizer= adam , metrics=['accuracy'])\n","    \n","    return model_m"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rlkU0AKMGTnX","colab_type":"code","colab":{}},"cell_type":"code","source":["def conv1d_model(num_features):\n","\n","    model_m = Sequential()\n","    model_m.add(Dense(1024, activation='relu',input_shape=(17,)))\n","    model_m.add(Dropout(0.5))\n","    model_m.add(Dense(512, activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n","    model_m.add(Dropout(0.2))\n","    model_m.add(Dense(1,activation='sigmoid'))\n","    \n","    adam= Adam(lr=0.0001)\n","    \n","    model_m.compile(loss='binary_crossentropy', optimizer= adam , metrics=['accuracy'])\n","    \n","    return model_m"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uAxAyh3_x8MV","colab_type":"code","colab":{}},"cell_type":"code","source":["model_m = conv1d_model(17)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jFlAhkWQQf_J","colab_type":"code","outputId":"75c65e00-ef6a-402d-83be-e4ddb6918a34","executionInfo":{"status":"error","timestamp":1553290496569,"user_tz":-60,"elapsed":2837,"user":{"displayName":"Francisco del Valle Bas","photoUrl":"","userId":"13762240210727807878"}},"colab":{"base_uri":"https://localhost:8080/","height":232}},"cell_type":"code","source":["from sklearn import svm\n","clf = svm.SVC(gamma='auto')\n","clf.fit(X_train, y_train) \n","\n","y_pred = clf.predict(X_test)\n","\n","print(classification_report(y_test,y_pred))\n","print(confusion_matrix(y_test,y_pred))\n","\n","accuracySVC = accuracy_score(y_test, y_pred)\n","\n","print(\"El accuracy obtenido es: \",accuracySVC)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-e04b763eee0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'classification_report' is not defined"]}]},{"metadata":{"id":"JR3KNWIdx8x-","colab_type":"code","outputId":"113b6077-6d8c-41af-e611-e93b145d8d91","executionInfo":{"status":"ok","timestamp":1553293113060,"user_tz":-60,"elapsed":24404,"user":{"displayName":"Francisco del Valle Bas","photoUrl":"","userId":"13762240210727807878"}},"colab":{"base_uri":"https://localhost:8080/","height":13705}},"cell_type":"code","source":["\n","rlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=40, min_delta=1E-7, verbose=1)\n","es = EarlyStopping(monitor='val_acc', mode='min', verbose=1, patience=400)\n","mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n","\n","history = model_m.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2000, verbose=1, callbacks=[es, mcp_save])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 208 samples, validate on 53 samples\n","Epoch 1/2000\n","208/208 [==============================] - 0s 237us/step - loss: 0.4774 - acc: 0.7837 - val_loss: 0.5067 - val_acc: 0.8113\n","Epoch 2/2000\n","208/208 [==============================] - 0s 223us/step - loss: 0.5473 - acc: 0.7837 - val_loss: 0.5082 - val_acc: 0.8302\n","Epoch 3/2000\n","208/208 [==============================] - 0s 232us/step - loss: 0.5435 - acc: 0.7356 - val_loss: 0.5055 - val_acc: 0.8113\n","Epoch 4/2000\n","208/208 [==============================] - 0s 226us/step - loss: 0.5392 - acc: 0.7548 - val_loss: 0.5064 - val_acc: 0.8113\n","Epoch 5/2000\n","208/208 [==============================] - 0s 221us/step - loss: 0.4996 - acc: 0.7548 - val_loss: 0.5100 - val_acc: 0.8302\n","Epoch 6/2000\n","208/208 [==============================] - 0s 252us/step - loss: 0.5474 - acc: 0.7740 - val_loss: 0.5073 - val_acc: 0.8302\n","Epoch 7/2000\n","208/208 [==============================] - 0s 265us/step - loss: 0.5372 - acc: 0.7500 - val_loss: 0.5090 - val_acc: 0.8302\n","Epoch 8/2000\n","208/208 [==============================] - 0s 223us/step - loss: 0.5675 - acc: 0.7500 - val_loss: 0.5090 - val_acc: 0.8302\n","Epoch 9/2000\n","208/208 [==============================] - 0s 218us/step - loss: 0.5338 - acc: 0.7692 - val_loss: 0.5103 - val_acc: 0.8302\n","Epoch 10/2000\n","208/208 [==============================] - 0s 230us/step - loss: 0.5192 - acc: 0.7644 - val_loss: 0.5078 - val_acc: 0.8113\n","Epoch 11/2000\n","208/208 [==============================] - 0s 226us/step - loss: 0.5301 - acc: 0.7788 - val_loss: 0.5067 - val_acc: 0.8302\n","Epoch 12/2000\n","208/208 [==============================] - 0s 228us/step - loss: 0.5203 - acc: 0.7740 - val_loss: 0.5053 - val_acc: 0.8302\n","Epoch 13/2000\n","208/208 [==============================] - 0s 227us/step - loss: 0.5215 - acc: 0.7933 - val_loss: 0.5084 - val_acc: 0.8302\n","Epoch 14/2000\n","208/208 [==============================] - 0s 230us/step - loss: 0.5291 - acc: 0.7596 - val_loss: 0.5041 - val_acc: 0.8302\n","Epoch 15/2000\n","208/208 [==============================] - 0s 254us/step - loss: 0.5176 - acc: 0.8173 - val_loss: 0.5005 - val_acc: 0.8302\n","Epoch 16/2000\n","208/208 [==============================] - 0s 239us/step - loss: 0.5311 - acc: 0.7644 - val_loss: 0.5008 - val_acc: 0.8302\n","Epoch 17/2000\n","208/208 [==============================] - 0s 247us/step - loss: 0.5582 - acc: 0.7404 - val_loss: 0.5045 - val_acc: 0.8302\n","Epoch 18/2000\n","208/208 [==============================] - 0s 240us/step - loss: 0.5196 - acc: 0.7644 - val_loss: 0.5012 - val_acc: 0.8302\n","Epoch 19/2000\n","208/208 [==============================] - 0s 242us/step - loss: 0.5575 - acc: 0.7452 - val_loss: 0.5004 - val_acc: 0.8302\n","Epoch 20/2000\n","208/208 [==============================] - 0s 241us/step - loss: 0.5368 - acc: 0.7885 - val_loss: 0.4992 - val_acc: 0.8302\n","Epoch 21/2000\n","208/208 [==============================] - 0s 250us/step - loss: 0.5578 - acc: 0.7260 - val_loss: 0.5016 - val_acc: 0.8302\n","Epoch 22/2000\n","208/208 [==============================] - 0s 227us/step - loss: 0.5017 - acc: 0.7644 - val_loss: 0.5004 - val_acc: 0.8302\n","Epoch 23/2000\n","208/208 [==============================] - 0s 293us/step - loss: 0.5048 - acc: 0.7692 - val_loss: 0.4968 - val_acc: 0.8491\n","Epoch 24/2000\n","208/208 [==============================] - 0s 223us/step - loss: 0.5273 - acc: 0.7548 - val_loss: 0.4958 - val_acc: 0.8491\n","Epoch 25/2000\n","208/208 [==============================] - 0s 234us/step - loss: 0.5104 - acc: 0.7788 - val_loss: 0.4952 - val_acc: 0.8302\n","Epoch 26/2000\n","208/208 [==============================] - 0s 220us/step - loss: 0.5151 - acc: 0.7837 - val_loss: 0.5066 - val_acc: 0.8491\n","Epoch 27/2000\n","208/208 [==============================] - 0s 220us/step - loss: 0.5463 - acc: 0.7596 - val_loss: 0.4941 - val_acc: 0.8302\n","Epoch 28/2000\n","208/208 [==============================] - 0s 231us/step - loss: 0.5134 - acc: 0.7933 - val_loss: 0.4911 - val_acc: 0.8302\n","Epoch 29/2000\n","208/208 [==============================] - 0s 218us/step - loss: 0.4950 - acc: 0.7981 - val_loss: 0.4902 - val_acc: 0.8302\n","Epoch 30/2000\n","208/208 [==============================] - 0s 226us/step - loss: 0.4979 - acc: 0.7933 - val_loss: 0.4933 - val_acc: 0.8113\n","Epoch 31/2000\n","208/208 [==============================] - 0s 233us/step - loss: 0.5232 - acc: 0.7404 - val_loss: 0.4928 - val_acc: 0.8302\n","Epoch 32/2000\n","208/208 [==============================] - 0s 218us/step - loss: 0.5256 - acc: 0.7548 - val_loss: 0.4900 - val_acc: 0.8302\n","Epoch 33/2000\n","208/208 [==============================] - 0s 219us/step - loss: 0.5407 - acc: 0.7740 - val_loss: 0.4891 - val_acc: 0.8302\n","Epoch 34/2000\n","208/208 [==============================] - 0s 226us/step - loss: 0.5183 - acc: 0.7692 - val_loss: 0.4897 - val_acc: 0.8302\n","Epoch 35/2000\n","208/208 [==============================] - 0s 225us/step - loss: 0.5143 - acc: 0.7596 - val_loss: 0.4939 - val_acc: 0.8491\n","Epoch 36/2000\n","208/208 [==============================] - 0s 222us/step - loss: 0.5435 - acc: 0.7548 - val_loss: 0.4928 - val_acc: 0.8302\n","Epoch 37/2000\n","208/208 [==============================] - 0s 223us/step - loss: 0.4654 - acc: 0.8029 - val_loss: 0.4857 - val_acc: 0.8302\n","Epoch 38/2000\n","208/208 [==============================] - 0s 231us/step - loss: 0.4797 - acc: 0.8077 - val_loss: 0.4930 - val_acc: 0.8679\n","Epoch 39/2000\n","208/208 [==============================] - 0s 238us/step - loss: 0.4998 - acc: 0.7548 - val_loss: 0.4828 - val_acc: 0.8302\n","Epoch 40/2000\n","208/208 [==============================] - 0s 221us/step - loss: 0.5293 - acc: 0.7837 - val_loss: 0.4822 - val_acc: 0.8302\n","Epoch 41/2000\n","208/208 [==============================] - 0s 229us/step - loss: 0.5152 - acc: 0.7837 - val_loss: 0.4820 - val_acc: 0.8302\n","Epoch 42/2000\n","208/208 [==============================] - 0s 236us/step - loss: 0.5358 - acc: 0.7548 - val_loss: 0.4834 - val_acc: 0.8491\n","Epoch 43/2000\n","208/208 [==============================] - 0s 219us/step - loss: 0.4846 - acc: 0.7788 - val_loss: 0.4787 - val_acc: 0.8491\n","Epoch 44/2000\n","208/208 [==============================] - 0s 223us/step - loss: 0.4931 - acc: 0.7933 - val_loss: 0.4751 - val_acc: 0.8302\n","Epoch 45/2000\n","208/208 [==============================] - 0s 233us/step - loss: 0.5171 - acc: 0.7596 - val_loss: 0.4850 - val_acc: 0.8113\n","Epoch 46/2000\n","208/208 [==============================] - 0s 220us/step - loss: 0.4885 - acc: 0.7788 - val_loss: 0.4821 - val_acc: 0.8491\n","Epoch 47/2000\n","208/208 [==============================] - 0s 218us/step - loss: 0.4718 - acc: 0.8317 - val_loss: 0.4807 - val_acc: 0.8491\n","Epoch 48/2000\n","208/208 [==============================] - 0s 228us/step - loss: 0.5206 - acc: 0.7740 - val_loss: 0.4789 - val_acc: 0.8491\n","Epoch 49/2000\n","208/208 [==============================] - 0s 216us/step - loss: 0.5727 - acc: 0.7308 - val_loss: 0.4766 - val_acc: 0.8302\n","Epoch 50/2000\n","208/208 [==============================] - 0s 239us/step - loss: 0.4922 - acc: 0.7981 - val_loss: 0.4783 - val_acc: 0.8491\n","Epoch 51/2000\n","208/208 [==============================] - 0s 234us/step - loss: 0.4762 - acc: 0.7837 - val_loss: 0.4753 - val_acc: 0.8491\n","Epoch 52/2000\n","208/208 [==============================] - 0s 243us/step - loss: 0.5081 - acc: 0.7548 - val_loss: 0.4743 - val_acc: 0.8302\n","Epoch 53/2000\n","208/208 [==============================] - 0s 254us/step - loss: 0.5128 - acc: 0.7740 - val_loss: 0.4752 - val_acc: 0.8302\n","Epoch 54/2000\n","208/208 [==============================] - 0s 244us/step - loss: 0.5177 - acc: 0.7740 - val_loss: 0.4738 - val_acc: 0.8491\n","Epoch 55/2000\n","208/208 [==============================] - 0s 223us/step - loss: 0.5447 - acc: 0.7596 - val_loss: 0.4761 - val_acc: 0.8491\n","Epoch 56/2000\n","208/208 [==============================] - 0s 221us/step - loss: 0.4985 - acc: 0.7837 - val_loss: 0.4786 - val_acc: 0.8491\n","Epoch 57/2000\n","208/208 [==============================] - 0s 243us/step - loss: 0.5385 - acc: 0.7788 - val_loss: 0.4827 - val_acc: 0.8679\n","Epoch 58/2000\n","208/208 [==============================] - 0s 241us/step - loss: 0.5110 - acc: 0.7788 - val_loss: 0.4757 - val_acc: 0.8491\n","Epoch 59/2000\n","208/208 [==============================] - 0s 247us/step - loss: 0.4740 - acc: 0.7933 - val_loss: 0.4755 - val_acc: 0.8491\n","Epoch 60/2000\n","208/208 [==============================] - 0s 223us/step - loss: 0.5061 - acc: 0.7692 - val_loss: 0.4774 - val_acc: 0.8491\n","Epoch 61/2000\n","208/208 [==============================] - 0s 241us/step - loss: 0.4942 - acc: 0.7837 - val_loss: 0.4735 - val_acc: 0.8491\n","Epoch 62/2000\n","208/208 [==============================] - 0s 236us/step - loss: 0.4755 - acc: 0.8269 - val_loss: 0.4694 - val_acc: 0.8491\n","Epoch 63/2000\n","208/208 [==============================] - 0s 228us/step - loss: 0.5136 - acc: 0.7933 - val_loss: 0.4685 - val_acc: 0.8491\n","Epoch 64/2000\n","208/208 [==============================] - 0s 215us/step - loss: 0.4875 - acc: 0.8029 - val_loss: 0.4680 - val_acc: 0.8491\n","Epoch 65/2000\n","208/208 [==============================] - 0s 222us/step - loss: 0.5065 - acc: 0.7788 - val_loss: 0.4697 - val_acc: 0.8491\n","Epoch 66/2000\n","208/208 [==============================] - 0s 233us/step - loss: 0.4849 - acc: 0.7981 - val_loss: 0.4725 - val_acc: 0.8679\n","Epoch 67/2000\n","208/208 [==============================] - 0s 217us/step - loss: 0.5124 - acc: 0.8029 - val_loss: 0.4642 - val_acc: 0.8491\n","Epoch 68/2000\n","208/208 [==============================] - 0s 259us/step - loss: 0.5110 - acc: 0.7981 - val_loss: 0.4642 - val_acc: 0.8491\n","Epoch 69/2000\n","208/208 [==============================] - 0s 229us/step - loss: 0.5080 - acc: 0.7740 - val_loss: 0.4648 - val_acc: 0.8491\n","Epoch 70/2000\n","208/208 [==============================] - 0s 225us/step - loss: 0.5046 - acc: 0.7837 - val_loss: 0.4675 - val_acc: 0.8491\n","Epoch 71/2000\n","208/208 [==============================] - 0s 232us/step - loss: 0.5177 - acc: 0.7885 - val_loss: 0.4638 - val_acc: 0.8491\n","Epoch 72/2000\n","208/208 [==============================] - 0s 237us/step - loss: 0.5188 - acc: 0.7837 - val_loss: 0.4734 - val_acc: 0.8679\n","Epoch 73/2000\n","208/208 [==============================] - 0s 232us/step - loss: 0.5145 - acc: 0.7692 - val_loss: 0.4644 - val_acc: 0.8491\n","Epoch 74/2000\n","208/208 [==============================] - 0s 236us/step - loss: 0.5092 - acc: 0.7837 - val_loss: 0.4640 - val_acc: 0.8491\n","Epoch 75/2000\n","208/208 [==============================] - 0s 235us/step - loss: 0.5486 - acc: 0.7644 - val_loss: 0.4631 - val_acc: 0.8491\n","Epoch 76/2000\n","208/208 [==============================] - 0s 231us/step - loss: 0.4653 - acc: 0.7788 - val_loss: 0.4626 - val_acc: 0.8491\n","Epoch 77/2000\n","208/208 [==============================] - 0s 238us/step - loss: 0.5091 - acc: 0.7837 - val_loss: 0.4608 - val_acc: 0.8491\n","Epoch 78/2000\n","208/208 [==============================] - 0s 226us/step - loss: 0.4759 - acc: 0.7981 - val_loss: 0.4602 - val_acc: 0.8491\n","Epoch 79/2000\n","208/208 [==============================] - 0s 219us/step - loss: 0.4835 - acc: 0.7788 - val_loss: 0.4595 - val_acc: 0.8491\n","Epoch 80/2000\n","208/208 [==============================] - 0s 216us/step - loss: 0.5388 - acc: 0.7644 - val_loss: 0.4667 - val_acc: 0.8679\n","Epoch 81/2000\n","208/208 [==============================] - 0s 220us/step - loss: 0.4685 - acc: 0.8173 - val_loss: 0.4602 - val_acc: 0.8491\n","Epoch 82/2000\n","208/208 [==============================] - 0s 221us/step - loss: 0.4900 - acc: 0.8029 - val_loss: 0.4674 - val_acc: 0.8491\n","Epoch 83/2000\n","208/208 [==============================] - 0s 211us/step - loss: 0.5108 - acc: 0.7885 - val_loss: 0.4581 - val_acc: 0.8491\n","Epoch 84/2000\n","208/208 [==============================] - 0s 225us/step - loss: 0.4988 - acc: 0.7740 - val_loss: 0.4633 - val_acc: 0.8679\n","Epoch 85/2000\n","208/208 [==============================] - 0s 230us/step - loss: 0.4528 - acc: 0.8269 - val_loss: 0.4579 - val_acc: 0.8491\n","Epoch 86/2000\n","208/208 [==============================] - 0s 216us/step - loss: 0.4907 - acc: 0.7692 - val_loss: 0.4562 - val_acc: 0.8679\n","Epoch 87/2000\n","208/208 [==============================] - 0s 222us/step - loss: 0.4829 - acc: 0.7788 - val_loss: 0.4578 - val_acc: 0.8491\n","Epoch 88/2000\n","208/208 [==============================] - 0s 230us/step - loss: 0.4862 - acc: 0.7596 - val_loss: 0.4602 - val_acc: 0.8679\n","Epoch 89/2000\n","208/208 [==============================] - 0s 223us/step - loss: 0.4922 - acc: 0.7837 - val_loss: 0.4653 - val_acc: 0.8491\n","Epoch 90/2000\n","208/208 [==============================] - 0s 239us/step - loss: 0.5014 - acc: 0.8077 - val_loss: 0.4638 - val_acc: 0.8491\n","Epoch 91/2000\n","208/208 [==============================] - 0s 262us/step - loss: 0.4420 - acc: 0.8317 - val_loss: 0.4621 - val_acc: 0.8491\n","Epoch 92/2000\n","208/208 [==============================] - 0s 238us/step - loss: 0.4769 - acc: 0.7933 - val_loss: 0.4612 - val_acc: 0.8491\n","Epoch 93/2000\n","208/208 [==============================] - 0s 220us/step - loss: 0.4897 - acc: 0.7740 - val_loss: 0.4629 - val_acc: 0.8491\n","Epoch 94/2000\n","208/208 [==============================] - 0s 221us/step - loss: 0.4793 - acc: 0.7933 - val_loss: 0.4616 - val_acc: 0.8491\n","Epoch 95/2000\n","208/208 [==============================] - 0s 218us/step - loss: 0.5197 - acc: 0.8125 - val_loss: 0.4644 - val_acc: 0.8679\n","Epoch 96/2000\n","208/208 [==============================] - 0s 242us/step - loss: 0.4854 - acc: 0.7933 - val_loss: 0.4626 - val_acc: 0.8491\n","Epoch 97/2000\n","208/208 [==============================] - 0s 230us/step - loss: 0.4674 - acc: 0.8125 - val_loss: 0.4633 - val_acc: 0.8679\n","Epoch 98/2000\n","208/208 [==============================] - 0s 238us/step - loss: 0.5361 - acc: 0.7837 - val_loss: 0.4631 - val_acc: 0.8679\n","Epoch 99/2000\n","208/208 [==============================] - 0s 243us/step - loss: 0.4910 - acc: 0.8029 - val_loss: 0.4614 - val_acc: 0.8491\n","Epoch 100/2000\n","208/208 [==============================] - 0s 263us/step - loss: 0.4854 - acc: 0.7981 - val_loss: 0.4558 - val_acc: 0.8491\n","Epoch 101/2000\n","208/208 [==============================] - 0s 249us/step - loss: 0.4728 - acc: 0.8029 - val_loss: 0.4536 - val_acc: 0.8679\n","Epoch 102/2000\n","208/208 [==============================] - 0s 220us/step - loss: 0.5251 - acc: 0.7692 - val_loss: 0.4539 - val_acc: 0.8679\n","Epoch 103/2000\n","208/208 [==============================] - 0s 223us/step - loss: 0.4744 - acc: 0.7933 - val_loss: 0.4520 - val_acc: 0.8491\n","Epoch 104/2000\n","208/208 [==============================] - 0s 216us/step - loss: 0.4819 - acc: 0.7933 - val_loss: 0.4598 - val_acc: 0.8679\n","Epoch 105/2000\n","208/208 [==============================] - 0s 216us/step - loss: 0.4810 - acc: 0.7740 - val_loss: 0.4475 - val_acc: 0.8491\n","Epoch 106/2000\n","208/208 [==============================] - 0s 223us/step - loss: 0.4611 - acc: 0.7692 - val_loss: 0.4486 - val_acc: 0.8491\n","Epoch 107/2000\n","208/208 [==============================] - 0s 212us/step - loss: 0.4754 - acc: 0.8317 - val_loss: 0.4479 - val_acc: 0.8491\n","Epoch 108/2000\n","208/208 [==============================] - 0s 280us/step - loss: 0.4903 - acc: 0.7885 - val_loss: 0.4538 - val_acc: 0.8491\n","Epoch 109/2000\n","208/208 [==============================] - 0s 232us/step - loss: 0.4718 - acc: 0.7788 - val_loss: 0.4518 - val_acc: 0.8491\n","Epoch 110/2000\n","208/208 [==============================] - 0s 226us/step - loss: 0.4806 - acc: 0.7885 - val_loss: 0.4515 - val_acc: 0.8679\n","Epoch 111/2000\n","208/208 [==============================] - 0s 223us/step - loss: 0.4770 - acc: 0.7837 - val_loss: 0.4519 - val_acc: 0.8491\n","Epoch 112/2000\n","208/208 [==============================] - 0s 220us/step - loss: 0.5454 - acc: 0.7933 - val_loss: 0.4498 - val_acc: 0.8679\n","Epoch 113/2000\n","208/208 [==============================] - 0s 222us/step - loss: 0.4729 - acc: 0.8173 - val_loss: 0.4479 - val_acc: 0.8679\n","Epoch 114/2000\n","208/208 [==============================] - 0s 238us/step - loss: 0.4731 - acc: 0.7885 - val_loss: 0.4492 - val_acc: 0.8679\n","Epoch 115/2000\n","208/208 [==============================] - 0s 248us/step - loss: 0.4427 - acc: 0.8077 - val_loss: 0.4468 - val_acc: 0.8491\n","Epoch 116/2000\n","208/208 [==============================] - 0s 227us/step - loss: 0.5019 - acc: 0.8125 - val_loss: 0.4438 - val_acc: 0.8491\n","Epoch 117/2000\n","208/208 [==============================] - 0s 222us/step - loss: 0.4884 - acc: 0.7788 - val_loss: 0.4705 - val_acc: 0.8679\n","Epoch 118/2000\n","208/208 [==============================] - 0s 222us/step - loss: 0.4927 - acc: 0.7933 - val_loss: 0.4513 - val_acc: 0.8679\n","Epoch 119/2000\n","208/208 [==============================] - 0s 211us/step - loss: 0.4845 - acc: 0.7885 - val_loss: 0.4495 - val_acc: 0.8679\n","Epoch 120/2000\n","208/208 [==============================] - 0s 217us/step - loss: 0.5463 - acc: 0.7740 - val_loss: 0.4498 - val_acc: 0.8679\n","Epoch 121/2000\n","208/208 [==============================] - 0s 219us/step - loss: 0.4795 - acc: 0.7981 - val_loss: 0.4620 - val_acc: 0.8679\n","Epoch 122/2000\n","208/208 [==============================] - 0s 218us/step - loss: 0.4595 - acc: 0.8125 - val_loss: 0.4492 - val_acc: 0.8491\n","Epoch 123/2000\n","208/208 [==============================] - 0s 226us/step - loss: 0.4809 - acc: 0.8029 - val_loss: 0.4506 - val_acc: 0.8679\n","Epoch 124/2000\n","208/208 [==============================] - 0s 235us/step - loss: 0.4915 - acc: 0.8125 - val_loss: 0.4449 - val_acc: 0.8679\n","Epoch 125/2000\n","208/208 [==============================] - 0s 234us/step - loss: 0.4273 - acc: 0.7933 - val_loss: 0.4520 - val_acc: 0.8679\n","Epoch 126/2000\n","208/208 [==============================] - 0s 228us/step - loss: 0.4914 - acc: 0.7740 - val_loss: 0.4468 - val_acc: 0.8679\n","Epoch 127/2000\n","208/208 [==============================] - 0s 249us/step - loss: 0.4576 - acc: 0.7885 - val_loss: 0.4438 - val_acc: 0.8491\n","Epoch 128/2000\n","208/208 [==============================] - 0s 245us/step - loss: 0.4763 - acc: 0.7596 - val_loss: 0.4426 - val_acc: 0.8491\n","Epoch 129/2000\n","208/208 [==============================] - 0s 240us/step - loss: 0.5170 - acc: 0.7981 - val_loss: 0.4402 - val_acc: 0.8491\n","Epoch 130/2000\n","208/208 [==============================] - 0s 224us/step - loss: 0.4573 - acc: 0.8221 - val_loss: 0.4383 - val_acc: 0.8491\n","Epoch 131/2000\n","208/208 [==============================] - 0s 229us/step - loss: 0.4949 - acc: 0.7933 - val_loss: 0.4387 - val_acc: 0.8491\n","Epoch 132/2000\n","208/208 [==============================] - 0s 216us/step - loss: 0.4538 - acc: 0.8221 - val_loss: 0.4425 - val_acc: 0.8679\n","Epoch 133/2000\n","208/208 [==============================] - 0s 221us/step - loss: 0.4494 - acc: 0.8029 - val_loss: 0.4450 - val_acc: 0.8868\n","Epoch 134/2000\n","208/208 [==============================] - 0s 231us/step - loss: 0.4740 - acc: 0.7644 - val_loss: 0.4424 - val_acc: 0.8868\n","Epoch 135/2000\n","208/208 [==============================] - 0s 220us/step - loss: 0.4470 - acc: 0.7981 - val_loss: 0.4435 - val_acc: 0.8491\n","Epoch 136/2000\n","208/208 [==============================] - 0s 234us/step - loss: 0.4620 - acc: 0.8029 - val_loss: 0.4412 - val_acc: 0.8491\n","Epoch 137/2000\n","208/208 [==============================] - 0s 227us/step - loss: 0.4462 - acc: 0.8269 - val_loss: 0.4414 - val_acc: 0.8491\n","Epoch 138/2000\n","208/208 [==============================] - 0s 256us/step - loss: 0.4553 - acc: 0.8269 - val_loss: 0.4398 - val_acc: 0.8491\n","Epoch 139/2000\n","208/208 [==============================] - 0s 223us/step - loss: 0.4757 - acc: 0.7933 - val_loss: 0.4387 - val_acc: 0.8679\n","Epoch 140/2000\n","208/208 [==============================] - 0s 237us/step - loss: 0.4480 - acc: 0.8269 - val_loss: 0.4377 - val_acc: 0.8491\n","Epoch 141/2000\n","208/208 [==============================] - 0s 221us/step - loss: 0.4746 - acc: 0.8077 - val_loss: 0.4393 - val_acc: 0.8491\n","Epoch 142/2000\n","208/208 [==============================] - 0s 233us/step - loss: 0.4706 - acc: 0.8125 - val_loss: 0.4477 - val_acc: 0.8679\n","Epoch 143/2000\n","208/208 [==============================] - 0s 236us/step - loss: 0.4783 - acc: 0.7885 - val_loss: 0.4447 - val_acc: 0.8491\n","Epoch 144/2000\n","208/208 [==============================] - 0s 243us/step - loss: 0.5037 - acc: 0.7740 - val_loss: 0.4479 - val_acc: 0.8679\n","Epoch 145/2000\n","208/208 [==============================] - 0s 289us/step - loss: 0.5067 - acc: 0.7596 - val_loss: 0.4477 - val_acc: 0.8491\n","Epoch 146/2000\n","208/208 [==============================] - 0s 216us/step - loss: 0.4733 - acc: 0.7933 - val_loss: 0.4485 - val_acc: 0.8679\n","Epoch 147/2000\n","208/208 [==============================] - 0s 224us/step - loss: 0.5058 - acc: 0.7740 - val_loss: 0.4458 - val_acc: 0.8491\n","Epoch 148/2000\n","208/208 [==============================] - 0s 236us/step - loss: 0.4180 - acc: 0.8173 - val_loss: 0.4468 - val_acc: 0.8679\n","Epoch 149/2000\n","208/208 [==============================] - 0s 231us/step - loss: 0.4876 - acc: 0.7596 - val_loss: 0.4457 - val_acc: 0.8491\n","Epoch 150/2000\n","208/208 [==============================] - 0s 228us/step - loss: 0.4475 - acc: 0.8125 - val_loss: 0.4481 - val_acc: 0.8491\n","Epoch 151/2000\n","208/208 [==============================] - 0s 234us/step - loss: 0.4757 - acc: 0.7933 - val_loss: 0.4486 - val_acc: 0.8491\n","Epoch 152/2000\n","208/208 [==============================] - 0s 249us/step - loss: 0.4625 - acc: 0.8221 - val_loss: 0.4477 - val_acc: 0.8491\n","Epoch 153/2000\n","208/208 [==============================] - 0s 245us/step - loss: 0.4494 - acc: 0.8317 - val_loss: 0.4476 - val_acc: 0.8491\n","Epoch 154/2000\n","208/208 [==============================] - 0s 241us/step - loss: 0.4117 - acc: 0.8365 - val_loss: 0.4482 - val_acc: 0.8679\n","Epoch 155/2000\n","208/208 [==============================] - 0s 235us/step - loss: 0.4647 - acc: 0.7933 - val_loss: 0.4475 - val_acc: 0.8491\n","Epoch 156/2000\n","208/208 [==============================] - 0s 235us/step - loss: 0.4389 - acc: 0.8221 - val_loss: 0.4452 - val_acc: 0.8491\n","Epoch 157/2000\n","208/208 [==============================] - 0s 266us/step - loss: 0.4733 - acc: 0.7837 - val_loss: 0.4449 - val_acc: 0.8679\n","Epoch 158/2000\n","208/208 [==============================] - 0s 234us/step - loss: 0.5224 - acc: 0.7837 - val_loss: 0.4450 - val_acc: 0.8679\n","Epoch 159/2000\n","208/208 [==============================] - 0s 225us/step - loss: 0.4186 - acc: 0.8317 - val_loss: 0.4412 - val_acc: 0.8491\n","Epoch 160/2000\n","208/208 [==============================] - 0s 240us/step - loss: 0.4436 - acc: 0.8029 - val_loss: 0.4403 - val_acc: 0.8491\n","Epoch 161/2000\n","208/208 [==============================] - 0s 235us/step - loss: 0.4874 - acc: 0.7885 - val_loss: 0.4400 - val_acc: 0.8491\n","Epoch 162/2000\n","208/208 [==============================] - 0s 241us/step - loss: 0.4213 - acc: 0.8654 - val_loss: 0.4406 - val_acc: 0.8491\n","Epoch 163/2000\n","208/208 [==============================] - 0s 253us/step - loss: 0.4299 - acc: 0.8317 - val_loss: 0.4408 - val_acc: 0.8491\n","Epoch 164/2000\n","208/208 [==============================] - 0s 241us/step - loss: 0.4532 - acc: 0.8125 - val_loss: 0.4430 - val_acc: 0.8491\n","Epoch 165/2000\n","208/208 [==============================] - 0s 296us/step - loss: 0.5201 - acc: 0.7548 - val_loss: 0.4470 - val_acc: 0.8679\n","Epoch 166/2000\n","208/208 [==============================] - 0s 232us/step - loss: 0.4564 - acc: 0.8269 - val_loss: 0.4430 - val_acc: 0.8491\n","Epoch 167/2000\n","208/208 [==============================] - 0s 234us/step - loss: 0.4638 - acc: 0.7885 - val_loss: 0.4362 - val_acc: 0.8491\n","Epoch 168/2000\n","208/208 [==============================] - 0s 238us/step - loss: 0.4516 - acc: 0.8173 - val_loss: 0.4373 - val_acc: 0.8679\n","Epoch 169/2000\n","208/208 [==============================] - 0s 233us/step - loss: 0.4486 - acc: 0.8221 - val_loss: 0.4405 - val_acc: 0.8679\n","Epoch 170/2000\n","208/208 [==============================] - 0s 242us/step - loss: 0.5253 - acc: 0.7596 - val_loss: 0.4384 - val_acc: 0.8491\n","Epoch 171/2000\n","208/208 [==============================] - 0s 249us/step - loss: 0.4903 - acc: 0.7644 - val_loss: 0.4389 - val_acc: 0.8679\n","Epoch 172/2000\n","208/208 [==============================] - 0s 242us/step - loss: 0.4739 - acc: 0.8125 - val_loss: 0.4374 - val_acc: 0.8868\n","Epoch 173/2000\n","208/208 [==============================] - 0s 240us/step - loss: 0.4314 - acc: 0.7933 - val_loss: 0.4399 - val_acc: 0.8491\n","Epoch 174/2000\n","208/208 [==============================] - 0s 235us/step - loss: 0.4623 - acc: 0.7981 - val_loss: 0.4380 - val_acc: 0.8491\n","Epoch 175/2000\n","208/208 [==============================] - 0s 231us/step - loss: 0.4808 - acc: 0.7981 - val_loss: 0.4381 - val_acc: 0.8491\n","Epoch 176/2000\n","208/208 [==============================] - 0s 242us/step - loss: 0.4099 - acc: 0.8462 - val_loss: 0.4393 - val_acc: 0.8491\n","Epoch 177/2000\n","208/208 [==============================] - 0s 233us/step - loss: 0.4786 - acc: 0.7692 - val_loss: 0.4424 - val_acc: 0.8491\n","Epoch 178/2000\n","208/208 [==============================] - 0s 246us/step - loss: 0.4455 - acc: 0.8221 - val_loss: 0.4380 - val_acc: 0.8491\n","Epoch 179/2000\n","208/208 [==============================] - 0s 225us/step - loss: 0.4287 - acc: 0.8125 - val_loss: 0.4354 - val_acc: 0.8679\n","Epoch 180/2000\n","208/208 [==============================] - 0s 224us/step - loss: 0.4332 - acc: 0.8125 - val_loss: 0.4344 - val_acc: 0.8679\n","Epoch 181/2000\n","208/208 [==============================] - 0s 222us/step - loss: 0.4645 - acc: 0.7933 - val_loss: 0.4349 - val_acc: 0.8491\n","Epoch 182/2000\n","208/208 [==============================] - 0s 233us/step - loss: 0.4573 - acc: 0.8077 - val_loss: 0.4307 - val_acc: 0.8491\n","Epoch 183/2000\n","208/208 [==============================] - 0s 255us/step - loss: 0.4783 - acc: 0.8029 - val_loss: 0.4299 - val_acc: 0.8679\n","Epoch 184/2000\n","208/208 [==============================] - 0s 222us/step - loss: 0.4269 - acc: 0.8558 - val_loss: 0.4291 - val_acc: 0.8491\n","Epoch 185/2000\n","208/208 [==============================] - 0s 233us/step - loss: 0.4698 - acc: 0.8173 - val_loss: 0.4283 - val_acc: 0.8679\n","Epoch 186/2000\n","208/208 [==============================] - 0s 237us/step - loss: 0.4552 - acc: 0.8125 - val_loss: 0.4300 - val_acc: 0.8491\n","Epoch 187/2000\n","208/208 [==============================] - 0s 213us/step - loss: 0.4458 - acc: 0.8365 - val_loss: 0.4333 - val_acc: 0.8868\n","Epoch 188/2000\n","208/208 [==============================] - 0s 206us/step - loss: 0.4372 - acc: 0.8413 - val_loss: 0.4316 - val_acc: 0.8679\n","Epoch 189/2000\n","208/208 [==============================] - 0s 219us/step - loss: 0.4202 - acc: 0.8413 - val_loss: 0.4305 - val_acc: 0.8491\n","Epoch 190/2000\n","208/208 [==============================] - 0s 223us/step - loss: 0.4376 - acc: 0.8413 - val_loss: 0.4319 - val_acc: 0.8491\n","Epoch 191/2000\n","208/208 [==============================] - 0s 219us/step - loss: 0.4355 - acc: 0.8365 - val_loss: 0.4333 - val_acc: 0.8491\n","Epoch 192/2000\n","208/208 [==============================] - 0s 224us/step - loss: 0.4268 - acc: 0.8221 - val_loss: 0.4360 - val_acc: 0.8491\n","Epoch 193/2000\n","208/208 [==============================] - 0s 231us/step - loss: 0.4525 - acc: 0.7933 - val_loss: 0.4389 - val_acc: 0.8679\n","Epoch 194/2000\n","208/208 [==============================] - 0s 235us/step - loss: 0.4017 - acc: 0.8510 - val_loss: 0.4351 - val_acc: 0.8491\n","Epoch 195/2000\n","208/208 [==============================] - 0s 230us/step - loss: 0.4413 - acc: 0.8029 - val_loss: 0.4361 - val_acc: 0.8868\n","Epoch 196/2000\n","208/208 [==============================] - 0s 254us/step - loss: 0.4625 - acc: 0.8125 - val_loss: 0.4357 - val_acc: 0.8491\n","Epoch 197/2000\n","208/208 [==============================] - 0s 257us/step - loss: 0.4896 - acc: 0.7885 - val_loss: 0.4377 - val_acc: 0.8491\n","Epoch 198/2000\n","208/208 [==============================] - 0s 225us/step - loss: 0.4821 - acc: 0.8125 - val_loss: 0.4414 - val_acc: 0.8868\n","Epoch 199/2000\n","208/208 [==============================] - 0s 236us/step - loss: 0.4160 - acc: 0.8462 - val_loss: 0.4404 - val_acc: 0.8491\n","Epoch 200/2000\n","208/208 [==============================] - 0s 244us/step - loss: 0.4336 - acc: 0.8173 - val_loss: 0.4440 - val_acc: 0.8491\n","Epoch 201/2000\n","208/208 [==============================] - 0s 299us/step - loss: 0.4630 - acc: 0.8269 - val_loss: 0.4502 - val_acc: 0.8491\n","Epoch 202/2000\n","208/208 [==============================] - 0s 224us/step - loss: 0.4342 - acc: 0.8125 - val_loss: 0.4493 - val_acc: 0.8679\n","Epoch 203/2000\n","208/208 [==============================] - 0s 216us/step - loss: 0.4582 - acc: 0.8173 - val_loss: 0.4507 - val_acc: 0.8491\n","Epoch 204/2000\n","208/208 [==============================] - 0s 236us/step - loss: 0.4902 - acc: 0.7740 - val_loss: 0.4423 - val_acc: 0.8491\n","Epoch 205/2000\n","208/208 [==============================] - 0s 222us/step - loss: 0.4718 - acc: 0.8077 - val_loss: 0.4413 - val_acc: 0.8679\n","Epoch 206/2000\n","208/208 [==============================] - 0s 241us/step - loss: 0.4157 - acc: 0.8606 - val_loss: 0.4381 - val_acc: 0.8868\n","Epoch 207/2000\n","208/208 [==============================] - 0s 223us/step - loss: 0.4417 - acc: 0.8077 - val_loss: 0.4398 - val_acc: 0.9057\n","Epoch 208/2000\n","208/208 [==============================] - 0s 233us/step - loss: 0.4578 - acc: 0.8077 - val_loss: 0.4456 - val_acc: 0.8679\n","Epoch 209/2000\n","208/208 [==============================] - 0s 247us/step - loss: 0.4790 - acc: 0.7692 - val_loss: 0.4338 - val_acc: 0.8491\n","Epoch 210/2000\n","208/208 [==============================] - 0s 233us/step - loss: 0.4044 - acc: 0.8365 - val_loss: 0.4416 - val_acc: 0.9057\n","Epoch 211/2000\n","208/208 [==============================] - 0s 242us/step - loss: 0.4553 - acc: 0.8125 - val_loss: 0.4338 - val_acc: 0.8679\n","Epoch 212/2000\n","208/208 [==============================] - 0s 248us/step - loss: 0.4571 - acc: 0.7981 - val_loss: 0.4361 - val_acc: 0.8491\n","Epoch 213/2000\n","208/208 [==============================] - 0s 230us/step - loss: 0.4452 - acc: 0.8125 - val_loss: 0.4349 - val_acc: 0.8491\n","Epoch 214/2000\n","208/208 [==============================] - 0s 231us/step - loss: 0.4607 - acc: 0.8029 - val_loss: 0.4482 - val_acc: 0.8868\n","Epoch 215/2000\n","208/208 [==============================] - 0s 224us/step - loss: 0.4508 - acc: 0.8221 - val_loss: 0.4379 - val_acc: 0.8491\n","Epoch 216/2000\n","208/208 [==============================] - 0s 221us/step - loss: 0.4489 - acc: 0.8125 - val_loss: 0.4382 - val_acc: 0.8491\n","Epoch 217/2000\n","208/208 [==============================] - 0s 240us/step - loss: 0.4354 - acc: 0.8269 - val_loss: 0.4373 - val_acc: 0.8491\n","Epoch 218/2000\n","208/208 [==============================] - 0s 235us/step - loss: 0.4774 - acc: 0.8173 - val_loss: 0.4416 - val_acc: 0.8491\n","Epoch 219/2000\n","208/208 [==============================] - 0s 235us/step - loss: 0.4499 - acc: 0.8173 - val_loss: 0.4408 - val_acc: 0.8491\n","Epoch 220/2000\n","208/208 [==============================] - 0s 227us/step - loss: 0.4621 - acc: 0.8125 - val_loss: 0.4391 - val_acc: 0.8679\n","Epoch 221/2000\n","208/208 [==============================] - 0s 279us/step - loss: 0.4554 - acc: 0.8269 - val_loss: 0.4439 - val_acc: 0.8679\n","Epoch 222/2000\n","208/208 [==============================] - 0s 237us/step - loss: 0.4481 - acc: 0.8221 - val_loss: 0.4390 - val_acc: 0.8491\n","Epoch 223/2000\n","208/208 [==============================] - 0s 222us/step - loss: 0.4419 - acc: 0.8413 - val_loss: 0.4368 - val_acc: 0.8679\n","Epoch 224/2000\n","208/208 [==============================] - 0s 234us/step - loss: 0.4718 - acc: 0.8077 - val_loss: 0.4362 - val_acc: 0.8491\n","Epoch 225/2000\n","208/208 [==============================] - 0s 227us/step - loss: 0.4386 - acc: 0.8365 - val_loss: 0.4368 - val_acc: 0.8679\n","Epoch 226/2000\n","208/208 [==============================] - 0s 240us/step - loss: 0.4565 - acc: 0.8269 - val_loss: 0.4338 - val_acc: 0.8679\n","Epoch 227/2000\n","208/208 [==============================] - 0s 233us/step - loss: 0.4670 - acc: 0.8269 - val_loss: 0.4338 - val_acc: 0.8679\n","Epoch 228/2000\n","208/208 [==============================] - 0s 228us/step - loss: 0.4169 - acc: 0.8365 - val_loss: 0.4357 - val_acc: 0.8491\n","Epoch 229/2000\n","208/208 [==============================] - 0s 238us/step - loss: 0.4834 - acc: 0.7837 - val_loss: 0.4409 - val_acc: 0.8679\n","Epoch 230/2000\n","208/208 [==============================] - 0s 228us/step - loss: 0.4474 - acc: 0.8029 - val_loss: 0.4344 - val_acc: 0.8679\n","Epoch 231/2000\n","208/208 [==============================] - 0s 242us/step - loss: 0.4336 - acc: 0.7981 - val_loss: 0.4413 - val_acc: 0.8868\n","Epoch 232/2000\n","208/208 [==============================] - 0s 227us/step - loss: 0.4741 - acc: 0.8125 - val_loss: 0.4317 - val_acc: 0.8491\n","Epoch 233/2000\n","208/208 [==============================] - 0s 250us/step - loss: 0.4167 - acc: 0.8269 - val_loss: 0.4318 - val_acc: 0.8491\n","Epoch 234/2000\n","208/208 [==============================] - 0s 225us/step - loss: 0.4304 - acc: 0.8269 - val_loss: 0.4327 - val_acc: 0.8679\n","Epoch 235/2000\n","208/208 [==============================] - 0s 234us/step - loss: 0.4155 - acc: 0.8221 - val_loss: 0.4313 - val_acc: 0.8491\n","Epoch 236/2000\n","208/208 [==============================] - 0s 239us/step - loss: 0.4029 - acc: 0.8221 - val_loss: 0.4317 - val_acc: 0.8491\n","Epoch 237/2000\n","208/208 [==============================] - 0s 217us/step - loss: 0.4445 - acc: 0.8077 - val_loss: 0.4331 - val_acc: 0.8491\n","Epoch 238/2000\n","208/208 [==============================] - 0s 233us/step - loss: 0.4480 - acc: 0.8125 - val_loss: 0.4353 - val_acc: 0.8491\n","Epoch 239/2000\n","208/208 [==============================] - 0s 241us/step - loss: 0.4460 - acc: 0.8125 - val_loss: 0.4365 - val_acc: 0.8679\n","Epoch 240/2000\n","208/208 [==============================] - 0s 247us/step - loss: 0.4204 - acc: 0.8317 - val_loss: 0.4383 - val_acc: 0.8491\n","Epoch 241/2000\n","208/208 [==============================] - 0s 225us/step - loss: 0.4279 - acc: 0.8125 - val_loss: 0.4388 - val_acc: 0.8491\n","Epoch 242/2000\n","208/208 [==============================] - 0s 267us/step - loss: 0.4373 - acc: 0.8221 - val_loss: 0.4346 - val_acc: 0.8491\n","Epoch 243/2000\n","208/208 [==============================] - 0s 231us/step - loss: 0.4393 - acc: 0.8125 - val_loss: 0.4311 - val_acc: 0.8491\n","Epoch 244/2000\n","208/208 [==============================] - 0s 229us/step - loss: 0.4403 - acc: 0.8029 - val_loss: 0.4300 - val_acc: 0.8491\n","Epoch 245/2000\n","208/208 [==============================] - 0s 239us/step - loss: 0.4615 - acc: 0.7933 - val_loss: 0.4299 - val_acc: 0.8491\n","Epoch 246/2000\n","208/208 [==============================] - 0s 219us/step - loss: 0.4201 - acc: 0.8221 - val_loss: 0.4289 - val_acc: 0.8491\n","Epoch 247/2000\n","208/208 [==============================] - 0s 233us/step - loss: 0.4489 - acc: 0.8077 - val_loss: 0.4277 - val_acc: 0.8491\n","Epoch 248/2000\n","208/208 [==============================] - 0s 227us/step - loss: 0.4493 - acc: 0.8269 - val_loss: 0.4302 - val_acc: 0.8491\n","Epoch 249/2000\n","208/208 [==============================] - 0s 226us/step - loss: 0.4103 - acc: 0.8413 - val_loss: 0.4313 - val_acc: 0.8679\n","Epoch 250/2000\n","208/208 [==============================] - 0s 227us/step - loss: 0.4719 - acc: 0.8077 - val_loss: 0.4286 - val_acc: 0.8491\n","Epoch 251/2000\n","208/208 [==============================] - 0s 226us/step - loss: 0.4675 - acc: 0.8221 - val_loss: 0.4278 - val_acc: 0.8679\n","Epoch 252/2000\n","208/208 [==============================] - 0s 231us/step - loss: 0.4054 - acc: 0.8510 - val_loss: 0.4251 - val_acc: 0.8491\n","Epoch 253/2000\n","208/208 [==============================] - 0s 231us/step - loss: 0.4530 - acc: 0.8173 - val_loss: 0.4238 - val_acc: 0.8868\n","Epoch 254/2000\n","208/208 [==============================] - 0s 233us/step - loss: 0.4456 - acc: 0.8125 - val_loss: 0.4265 - val_acc: 0.8868\n","Epoch 255/2000\n","208/208 [==============================] - 0s 222us/step - loss: 0.4246 - acc: 0.8510 - val_loss: 0.4279 - val_acc: 0.8491\n","Epoch 256/2000\n","208/208 [==============================] - 0s 206us/step - loss: 0.4391 - acc: 0.8317 - val_loss: 0.4308 - val_acc: 0.8491\n","Epoch 257/2000\n","208/208 [==============================] - 0s 220us/step - loss: 0.4787 - acc: 0.8173 - val_loss: 0.4307 - val_acc: 0.8491\n","Epoch 258/2000\n","208/208 [==============================] - 0s 229us/step - loss: 0.4325 - acc: 0.8125 - val_loss: 0.4296 - val_acc: 0.8491\n","Epoch 259/2000\n","208/208 [==============================] - 0s 218us/step - loss: 0.4375 - acc: 0.8077 - val_loss: 0.4286 - val_acc: 0.8491\n","Epoch 260/2000\n","208/208 [==============================] - 0s 268us/step - loss: 0.3793 - acc: 0.8702 - val_loss: 0.4301 - val_acc: 0.8679\n","Epoch 261/2000\n","208/208 [==============================] - 0s 243us/step - loss: 0.4527 - acc: 0.7788 - val_loss: 0.4267 - val_acc: 0.8679\n","Epoch 262/2000\n","208/208 [==============================] - 0s 230us/step - loss: 0.4704 - acc: 0.8125 - val_loss: 0.4231 - val_acc: 0.8679\n","Epoch 263/2000\n","208/208 [==============================] - 0s 223us/step - loss: 0.4369 - acc: 0.8221 - val_loss: 0.4236 - val_acc: 0.8679\n","Epoch 264/2000\n","208/208 [==============================] - 0s 231us/step - loss: 0.4573 - acc: 0.8077 - val_loss: 0.4242 - val_acc: 0.8679\n","Epoch 265/2000\n","208/208 [==============================] - 0s 221us/step - loss: 0.4442 - acc: 0.7981 - val_loss: 0.4244 - val_acc: 0.8679\n","Epoch 266/2000\n","208/208 [==============================] - 0s 260us/step - loss: 0.4237 - acc: 0.8077 - val_loss: 0.4268 - val_acc: 0.8491\n","Epoch 267/2000\n","208/208 [==============================] - 0s 213us/step - loss: 0.4363 - acc: 0.8365 - val_loss: 0.4222 - val_acc: 0.8679\n","Epoch 268/2000\n","208/208 [==============================] - 0s 244us/step - loss: 0.4542 - acc: 0.8077 - val_loss: 0.4220 - val_acc: 0.8868\n","Epoch 269/2000\n","208/208 [==============================] - 0s 232us/step - loss: 0.4190 - acc: 0.8221 - val_loss: 0.4221 - val_acc: 0.8491\n","Epoch 270/2000\n","208/208 [==============================] - 0s 217us/step - loss: 0.4383 - acc: 0.8269 - val_loss: 0.4256 - val_acc: 0.8679\n","Epoch 271/2000\n","208/208 [==============================] - 0s 208us/step - loss: 0.4053 - acc: 0.8413 - val_loss: 0.4329 - val_acc: 0.8679\n","Epoch 272/2000\n","208/208 [==============================] - 0s 229us/step - loss: 0.4645 - acc: 0.8077 - val_loss: 0.4431 - val_acc: 0.8679\n","Epoch 273/2000\n","208/208 [==============================] - 0s 217us/step - loss: 0.4122 - acc: 0.8365 - val_loss: 0.4396 - val_acc: 0.8679\n","Epoch 274/2000\n","208/208 [==============================] - 0s 229us/step - loss: 0.4468 - acc: 0.8125 - val_loss: 0.4408 - val_acc: 0.8491\n","Epoch 275/2000\n","208/208 [==============================] - 0s 267us/step - loss: 0.4035 - acc: 0.8125 - val_loss: 0.4343 - val_acc: 0.8679\n","Epoch 276/2000\n","208/208 [==============================] - 0s 257us/step - loss: 0.4599 - acc: 0.7837 - val_loss: 0.4321 - val_acc: 0.8491\n","Epoch 277/2000\n","208/208 [==============================] - 0s 225us/step - loss: 0.3776 - acc: 0.8462 - val_loss: 0.4288 - val_acc: 0.8491\n","Epoch 278/2000\n","208/208 [==============================] - 0s 222us/step - loss: 0.4505 - acc: 0.8462 - val_loss: 0.4306 - val_acc: 0.8491\n","Epoch 279/2000\n","208/208 [==============================] - 0s 232us/step - loss: 0.4245 - acc: 0.8317 - val_loss: 0.4271 - val_acc: 0.8491\n","Epoch 280/2000\n","208/208 [==============================] - 0s 247us/step - loss: 0.4167 - acc: 0.8558 - val_loss: 0.4281 - val_acc: 0.8679\n","Epoch 281/2000\n","208/208 [==============================] - 0s 245us/step - loss: 0.4381 - acc: 0.8365 - val_loss: 0.4275 - val_acc: 0.8491\n","Epoch 282/2000\n","208/208 [==============================] - 0s 245us/step - loss: 0.4308 - acc: 0.8029 - val_loss: 0.4281 - val_acc: 0.8491\n","Epoch 283/2000\n","208/208 [==============================] - 0s 243us/step - loss: 0.4346 - acc: 0.8173 - val_loss: 0.4293 - val_acc: 0.8491\n","Epoch 284/2000\n","208/208 [==============================] - 0s 239us/step - loss: 0.4489 - acc: 0.8029 - val_loss: 0.4323 - val_acc: 0.8491\n","Epoch 285/2000\n","208/208 [==============================] - 0s 215us/step - loss: 0.4190 - acc: 0.8221 - val_loss: 0.4309 - val_acc: 0.8491\n","Epoch 286/2000\n","208/208 [==============================] - 0s 225us/step - loss: 0.4189 - acc: 0.8365 - val_loss: 0.4314 - val_acc: 0.8491\n","Epoch 287/2000\n","208/208 [==============================] - 0s 240us/step - loss: 0.4418 - acc: 0.8269 - val_loss: 0.4327 - val_acc: 0.8491\n","Epoch 288/2000\n","208/208 [==============================] - 0s 213us/step - loss: 0.4533 - acc: 0.8077 - val_loss: 0.4291 - val_acc: 0.8491\n","Epoch 289/2000\n","208/208 [==============================] - 0s 248us/step - loss: 0.4297 - acc: 0.8173 - val_loss: 0.4284 - val_acc: 0.8491\n","Epoch 290/2000\n","208/208 [==============================] - 0s 237us/step - loss: 0.4103 - acc: 0.8317 - val_loss: 0.4298 - val_acc: 0.8491\n","Epoch 291/2000\n","208/208 [==============================] - 0s 217us/step - loss: 0.4182 - acc: 0.8125 - val_loss: 0.4257 - val_acc: 0.8491\n","Epoch 292/2000\n","208/208 [==============================] - 0s 227us/step - loss: 0.4413 - acc: 0.8365 - val_loss: 0.4255 - val_acc: 0.8679\n","Epoch 293/2000\n","208/208 [==============================] - 0s 227us/step - loss: 0.4339 - acc: 0.8125 - val_loss: 0.4253 - val_acc: 0.8679\n","Epoch 294/2000\n","208/208 [==============================] - 0s 230us/step - loss: 0.3761 - acc: 0.8510 - val_loss: 0.4253 - val_acc: 0.8491\n","Epoch 295/2000\n","208/208 [==============================] - 0s 229us/step - loss: 0.4623 - acc: 0.7885 - val_loss: 0.4306 - val_acc: 0.8679\n","Epoch 296/2000\n","208/208 [==============================] - 0s 284us/step - loss: 0.4229 - acc: 0.8125 - val_loss: 0.4302 - val_acc: 0.8679\n","Epoch 297/2000\n","208/208 [==============================] - 0s 231us/step - loss: 0.4097 - acc: 0.8317 - val_loss: 0.4308 - val_acc: 0.8679\n","Epoch 298/2000\n","208/208 [==============================] - 0s 230us/step - loss: 0.4211 - acc: 0.8317 - val_loss: 0.4306 - val_acc: 0.8491\n","Epoch 299/2000\n","208/208 [==============================] - 0s 223us/step - loss: 0.4412 - acc: 0.8173 - val_loss: 0.4276 - val_acc: 0.8679\n","Epoch 300/2000\n","208/208 [==============================] - 0s 225us/step - loss: 0.4260 - acc: 0.8221 - val_loss: 0.4252 - val_acc: 0.8491\n","Epoch 301/2000\n","208/208 [==============================] - 0s 237us/step - loss: 0.4213 - acc: 0.8365 - val_loss: 0.4267 - val_acc: 0.8868\n","Epoch 302/2000\n","208/208 [==============================] - 0s 235us/step - loss: 0.4167 - acc: 0.8269 - val_loss: 0.4267 - val_acc: 0.8491\n","Epoch 303/2000\n","208/208 [==============================] - 0s 247us/step - loss: 0.4323 - acc: 0.7981 - val_loss: 0.4312 - val_acc: 0.8491\n","Epoch 304/2000\n","208/208 [==============================] - 0s 233us/step - loss: 0.4108 - acc: 0.8269 - val_loss: 0.4344 - val_acc: 0.9057\n","Epoch 305/2000\n","208/208 [==============================] - 0s 237us/step - loss: 0.4234 - acc: 0.8317 - val_loss: 0.4269 - val_acc: 0.8868\n","Epoch 306/2000\n","208/208 [==============================] - 0s 225us/step - loss: 0.4183 - acc: 0.8317 - val_loss: 0.4294 - val_acc: 0.8491\n","Epoch 307/2000\n","208/208 [==============================] - 0s 221us/step - loss: 0.4259 - acc: 0.8173 - val_loss: 0.4307 - val_acc: 0.8491\n","Epoch 308/2000\n","208/208 [==============================] - 0s 248us/step - loss: 0.4699 - acc: 0.8029 - val_loss: 0.4342 - val_acc: 0.8491\n","Epoch 309/2000\n","208/208 [==============================] - 0s 227us/step - loss: 0.4098 - acc: 0.8413 - val_loss: 0.4315 - val_acc: 0.8491\n","Epoch 310/2000\n","208/208 [==============================] - 0s 236us/step - loss: 0.4079 - acc: 0.8413 - val_loss: 0.4375 - val_acc: 0.8679\n","Epoch 311/2000\n","208/208 [==============================] - 0s 229us/step - loss: 0.4157 - acc: 0.8413 - val_loss: 0.4305 - val_acc: 0.8679\n","Epoch 312/2000\n","208/208 [==============================] - 0s 224us/step - loss: 0.4556 - acc: 0.7981 - val_loss: 0.4294 - val_acc: 0.8491\n","Epoch 313/2000\n","208/208 [==============================] - 0s 241us/step - loss: 0.4354 - acc: 0.8173 - val_loss: 0.4308 - val_acc: 0.8679\n","Epoch 314/2000\n","208/208 [==============================] - 0s 241us/step - loss: 0.4207 - acc: 0.8365 - val_loss: 0.4290 - val_acc: 0.8491\n","Epoch 315/2000\n","208/208 [==============================] - 0s 234us/step - loss: 0.4309 - acc: 0.8413 - val_loss: 0.4280 - val_acc: 0.8679\n","Epoch 316/2000\n","208/208 [==============================] - 0s 281us/step - loss: 0.4257 - acc: 0.8173 - val_loss: 0.4288 - val_acc: 0.8491\n","Epoch 317/2000\n","208/208 [==============================] - 0s 240us/step - loss: 0.4273 - acc: 0.8029 - val_loss: 0.4300 - val_acc: 0.8868\n","Epoch 318/2000\n","208/208 [==============================] - 0s 257us/step - loss: 0.4126 - acc: 0.8365 - val_loss: 0.4297 - val_acc: 0.8491\n","Epoch 319/2000\n","208/208 [==============================] - 0s 223us/step - loss: 0.4332 - acc: 0.8221 - val_loss: 0.4312 - val_acc: 0.8491\n","Epoch 320/2000\n","208/208 [==============================] - 0s 223us/step - loss: 0.4515 - acc: 0.8077 - val_loss: 0.4335 - val_acc: 0.8679\n","Epoch 321/2000\n","208/208 [==============================] - 0s 237us/step - loss: 0.4118 - acc: 0.8510 - val_loss: 0.4304 - val_acc: 0.8679\n","Epoch 322/2000\n","208/208 [==============================] - 0s 224us/step - loss: 0.4354 - acc: 0.8462 - val_loss: 0.4298 - val_acc: 0.8491\n","Epoch 323/2000\n","208/208 [==============================] - 0s 240us/step - loss: 0.4148 - acc: 0.8125 - val_loss: 0.4315 - val_acc: 0.8679\n","Epoch 324/2000\n","208/208 [==============================] - 0s 231us/step - loss: 0.3903 - acc: 0.8413 - val_loss: 0.4325 - val_acc: 0.8491\n","Epoch 325/2000\n","208/208 [==============================] - 0s 224us/step - loss: 0.4362 - acc: 0.7981 - val_loss: 0.4408 - val_acc: 0.8679\n","Epoch 326/2000\n","208/208 [==============================] - 0s 248us/step - loss: 0.4175 - acc: 0.8269 - val_loss: 0.4345 - val_acc: 0.8491\n","Epoch 327/2000\n","208/208 [==============================] - 0s 239us/step - loss: 0.4182 - acc: 0.8269 - val_loss: 0.4332 - val_acc: 0.8491\n","Epoch 328/2000\n","208/208 [==============================] - 0s 228us/step - loss: 0.4263 - acc: 0.8269 - val_loss: 0.4324 - val_acc: 0.8868\n","Epoch 329/2000\n","208/208 [==============================] - 0s 246us/step - loss: 0.3933 - acc: 0.8365 - val_loss: 0.4292 - val_acc: 0.8868\n","Epoch 330/2000\n","208/208 [==============================] - 0s 252us/step - loss: 0.4077 - acc: 0.8317 - val_loss: 0.4302 - val_acc: 0.8491\n","Epoch 331/2000\n","208/208 [==============================] - 0s 241us/step - loss: 0.4195 - acc: 0.8221 - val_loss: 0.4261 - val_acc: 0.8491\n","Epoch 332/2000\n","208/208 [==============================] - 0s 240us/step - loss: 0.4144 - acc: 0.8317 - val_loss: 0.4264 - val_acc: 0.8868\n","Epoch 333/2000\n","208/208 [==============================] - 0s 239us/step - loss: 0.4162 - acc: 0.8365 - val_loss: 0.4318 - val_acc: 0.9057\n","Epoch 334/2000\n","208/208 [==============================] - 0s 243us/step - loss: 0.3825 - acc: 0.8558 - val_loss: 0.4274 - val_acc: 0.8679\n","Epoch 335/2000\n","208/208 [==============================] - 0s 249us/step - loss: 0.4308 - acc: 0.8221 - val_loss: 0.4360 - val_acc: 0.8491\n","Epoch 336/2000\n","208/208 [==============================] - 0s 282us/step - loss: 0.4456 - acc: 0.8269 - val_loss: 0.4419 - val_acc: 0.8491\n","Epoch 337/2000\n","208/208 [==============================] - 0s 229us/step - loss: 0.4443 - acc: 0.8269 - val_loss: 0.4316 - val_acc: 0.8491\n","Epoch 338/2000\n","208/208 [==============================] - 0s 240us/step - loss: 0.4125 - acc: 0.8125 - val_loss: 0.4291 - val_acc: 0.8679\n","Epoch 339/2000\n","208/208 [==============================] - 0s 240us/step - loss: 0.4297 - acc: 0.8269 - val_loss: 0.4260 - val_acc: 0.8868\n","Epoch 340/2000\n","208/208 [==============================] - 0s 230us/step - loss: 0.4152 - acc: 0.8269 - val_loss: 0.4260 - val_acc: 0.8491\n","Epoch 341/2000\n","208/208 [==============================] - 0s 228us/step - loss: 0.4025 - acc: 0.8029 - val_loss: 0.4263 - val_acc: 0.8491\n","Epoch 342/2000\n","208/208 [==============================] - 0s 226us/step - loss: 0.4243 - acc: 0.8462 - val_loss: 0.4221 - val_acc: 0.8491\n","Epoch 343/2000\n","208/208 [==============================] - 0s 239us/step - loss: 0.4081 - acc: 0.8462 - val_loss: 0.4269 - val_acc: 0.8491\n","Epoch 344/2000\n","208/208 [==============================] - 0s 264us/step - loss: 0.4308 - acc: 0.8125 - val_loss: 0.4262 - val_acc: 0.8679\n","Epoch 345/2000\n","208/208 [==============================] - 0s 235us/step - loss: 0.4356 - acc: 0.8125 - val_loss: 0.4306 - val_acc: 0.8491\n","Epoch 346/2000\n","208/208 [==============================] - 0s 228us/step - loss: 0.4248 - acc: 0.8029 - val_loss: 0.4323 - val_acc: 0.8679\n","Epoch 347/2000\n","208/208 [==============================] - 0s 245us/step - loss: 0.4084 - acc: 0.8462 - val_loss: 0.4317 - val_acc: 0.8679\n","Epoch 348/2000\n","208/208 [==============================] - 0s 236us/step - loss: 0.4209 - acc: 0.8221 - val_loss: 0.4402 - val_acc: 0.8679\n","Epoch 349/2000\n","208/208 [==============================] - 0s 230us/step - loss: 0.4359 - acc: 0.8413 - val_loss: 0.4384 - val_acc: 0.8679\n","Epoch 350/2000\n","208/208 [==============================] - 0s 239us/step - loss: 0.3940 - acc: 0.8510 - val_loss: 0.4319 - val_acc: 0.8679\n","Epoch 351/2000\n","208/208 [==============================] - 0s 230us/step - loss: 0.4184 - acc: 0.8173 - val_loss: 0.4365 - val_acc: 0.8491\n","Epoch 352/2000\n","208/208 [==============================] - 0s 243us/step - loss: 0.4382 - acc: 0.8365 - val_loss: 0.4304 - val_acc: 0.8491\n","Epoch 353/2000\n","208/208 [==============================] - 0s 242us/step - loss: 0.4065 - acc: 0.8317 - val_loss: 0.4308 - val_acc: 0.8679\n","Epoch 354/2000\n","208/208 [==============================] - 0s 237us/step - loss: 0.4037 - acc: 0.8029 - val_loss: 0.4340 - val_acc: 0.8679\n","Epoch 355/2000\n","208/208 [==============================] - 0s 248us/step - loss: 0.3866 - acc: 0.8462 - val_loss: 0.4395 - val_acc: 0.8491\n","Epoch 356/2000\n","208/208 [==============================] - 0s 296us/step - loss: 0.4462 - acc: 0.8365 - val_loss: 0.4414 - val_acc: 0.8679\n","Epoch 357/2000\n","208/208 [==============================] - 0s 233us/step - loss: 0.4237 - acc: 0.8077 - val_loss: 0.4432 - val_acc: 0.8679\n","Epoch 358/2000\n","208/208 [==============================] - 0s 230us/step - loss: 0.4425 - acc: 0.8077 - val_loss: 0.4362 - val_acc: 0.8679\n","Epoch 359/2000\n","208/208 [==============================] - 0s 244us/step - loss: 0.3717 - acc: 0.8462 - val_loss: 0.4313 - val_acc: 0.8679\n","Epoch 360/2000\n","208/208 [==============================] - 0s 232us/step - loss: 0.4252 - acc: 0.8173 - val_loss: 0.4301 - val_acc: 0.8679\n","Epoch 361/2000\n","208/208 [==============================] - 0s 251us/step - loss: 0.4284 - acc: 0.8029 - val_loss: 0.4276 - val_acc: 0.8491\n","Epoch 362/2000\n","208/208 [==============================] - 0s 229us/step - loss: 0.4156 - acc: 0.8173 - val_loss: 0.4229 - val_acc: 0.8679\n","Epoch 363/2000\n","208/208 [==============================] - 0s 230us/step - loss: 0.3709 - acc: 0.8413 - val_loss: 0.4307 - val_acc: 0.8868\n","Epoch 364/2000\n","208/208 [==============================] - 0s 234us/step - loss: 0.4128 - acc: 0.8510 - val_loss: 0.4334 - val_acc: 0.8491\n","Epoch 365/2000\n","208/208 [==============================] - 0s 225us/step - loss: 0.4003 - acc: 0.8365 - val_loss: 0.4392 - val_acc: 0.8491\n","Epoch 366/2000\n","208/208 [==============================] - 0s 254us/step - loss: 0.4194 - acc: 0.8317 - val_loss: 0.4444 - val_acc: 0.8679\n","Epoch 367/2000\n","208/208 [==============================] - 0s 231us/step - loss: 0.4176 - acc: 0.8125 - val_loss: 0.4440 - val_acc: 0.8491\n","Epoch 368/2000\n","208/208 [==============================] - 0s 226us/step - loss: 0.4149 - acc: 0.8077 - val_loss: 0.4422 - val_acc: 0.8679\n","Epoch 369/2000\n","208/208 [==============================] - 0s 234us/step - loss: 0.3623 - acc: 0.8606 - val_loss: 0.4408 - val_acc: 0.8679\n","Epoch 370/2000\n","208/208 [==============================] - 0s 238us/step - loss: 0.4001 - acc: 0.8558 - val_loss: 0.4401 - val_acc: 0.8679\n","Epoch 371/2000\n","208/208 [==============================] - 0s 238us/step - loss: 0.4280 - acc: 0.8173 - val_loss: 0.4388 - val_acc: 0.8679\n","Epoch 372/2000\n","208/208 [==============================] - 0s 245us/step - loss: 0.4511 - acc: 0.8029 - val_loss: 0.4451 - val_acc: 0.8491\n","Epoch 373/2000\n","208/208 [==============================] - 0s 245us/step - loss: 0.4419 - acc: 0.8269 - val_loss: 0.4499 - val_acc: 0.8679\n","Epoch 374/2000\n","208/208 [==============================] - 0s 240us/step - loss: 0.4516 - acc: 0.7788 - val_loss: 0.4494 - val_acc: 0.8491\n","Epoch 375/2000\n","208/208 [==============================] - 0s 234us/step - loss: 0.4404 - acc: 0.8510 - val_loss: 0.4503 - val_acc: 0.8679\n","Epoch 376/2000\n","208/208 [==============================] - 0s 288us/step - loss: 0.3951 - acc: 0.8317 - val_loss: 0.4500 - val_acc: 0.8491\n","Epoch 377/2000\n","208/208 [==============================] - 0s 222us/step - loss: 0.3909 - acc: 0.8317 - val_loss: 0.4495 - val_acc: 0.8491\n","Epoch 378/2000\n","208/208 [==============================] - 0s 214us/step - loss: 0.4157 - acc: 0.8077 - val_loss: 0.4451 - val_acc: 0.8491\n","Epoch 379/2000\n","208/208 [==============================] - 0s 238us/step - loss: 0.4181 - acc: 0.8317 - val_loss: 0.4427 - val_acc: 0.8679\n","Epoch 380/2000\n","208/208 [==============================] - 0s 225us/step - loss: 0.4209 - acc: 0.8221 - val_loss: 0.4406 - val_acc: 0.8679\n","Epoch 381/2000\n","208/208 [==============================] - 0s 234us/step - loss: 0.3797 - acc: 0.8510 - val_loss: 0.4453 - val_acc: 0.8491\n","Epoch 382/2000\n","208/208 [==============================] - 0s 253us/step - loss: 0.4124 - acc: 0.8317 - val_loss: 0.4513 - val_acc: 0.8679\n","Epoch 383/2000\n","208/208 [==============================] - 0s 240us/step - loss: 0.4011 - acc: 0.8462 - val_loss: 0.4497 - val_acc: 0.8679\n","Epoch 384/2000\n","208/208 [==============================] - 0s 221us/step - loss: 0.4171 - acc: 0.8173 - val_loss: 0.4480 - val_acc: 0.8679\n","Epoch 385/2000\n","208/208 [==============================] - 0s 247us/step - loss: 0.4103 - acc: 0.8462 - val_loss: 0.4462 - val_acc: 0.8679\n","Epoch 386/2000\n","208/208 [==============================] - 0s 231us/step - loss: 0.3902 - acc: 0.8269 - val_loss: 0.4457 - val_acc: 0.8679\n","Epoch 387/2000\n","208/208 [==============================] - 0s 228us/step - loss: 0.4299 - acc: 0.8365 - val_loss: 0.4464 - val_acc: 0.8679\n","Epoch 388/2000\n","208/208 [==============================] - 0s 229us/step - loss: 0.3739 - acc: 0.8510 - val_loss: 0.4469 - val_acc: 0.8679\n","Epoch 389/2000\n","208/208 [==============================] - 0s 245us/step - loss: 0.4064 - acc: 0.8221 - val_loss: 0.4507 - val_acc: 0.8491\n","Epoch 390/2000\n","208/208 [==============================] - 0s 233us/step - loss: 0.4136 - acc: 0.8221 - val_loss: 0.4506 - val_acc: 0.8679\n","Epoch 391/2000\n","208/208 [==============================] - 0s 241us/step - loss: 0.4109 - acc: 0.8413 - val_loss: 0.4539 - val_acc: 0.8679\n","Epoch 392/2000\n","208/208 [==============================] - 0s 241us/step - loss: 0.3730 - acc: 0.8606 - val_loss: 0.4553 - val_acc: 0.8679\n","Epoch 393/2000\n","208/208 [==============================] - 0s 237us/step - loss: 0.3933 - acc: 0.8510 - val_loss: 0.4547 - val_acc: 0.8679\n","Epoch 394/2000\n","208/208 [==============================] - 0s 239us/step - loss: 0.4171 - acc: 0.8269 - val_loss: 0.4540 - val_acc: 0.8679\n","Epoch 395/2000\n","208/208 [==============================] - 0s 239us/step - loss: 0.4115 - acc: 0.8317 - val_loss: 0.4534 - val_acc: 0.8679\n","Epoch 396/2000\n","208/208 [==============================] - 0s 307us/step - loss: 0.4155 - acc: 0.8269 - val_loss: 0.4493 - val_acc: 0.8679\n","Epoch 397/2000\n","208/208 [==============================] - 0s 228us/step - loss: 0.3859 - acc: 0.8558 - val_loss: 0.4456 - val_acc: 0.8491\n","Epoch 398/2000\n","208/208 [==============================] - 0s 229us/step - loss: 0.3756 - acc: 0.8462 - val_loss: 0.4410 - val_acc: 0.8679\n","Epoch 399/2000\n","208/208 [==============================] - 0s 231us/step - loss: 0.4408 - acc: 0.8125 - val_loss: 0.4471 - val_acc: 0.8679\n","Epoch 400/2000\n","208/208 [==============================] - 0s 227us/step - loss: 0.4273 - acc: 0.8173 - val_loss: 0.4402 - val_acc: 0.8679\n","Epoch 401/2000\n","208/208 [==============================] - 0s 252us/step - loss: 0.4076 - acc: 0.8221 - val_loss: 0.4433 - val_acc: 0.8491\n","Epoch 00401: early stopping\n"],"name":"stdout"}]},{"metadata":{"id":"_tJBe4iXd8at","colab_type":"code","outputId":"7ec635df-2b7d-4ebb-ebf5-80627c79c408","executionInfo":{"status":"ok","timestamp":1553293118264,"user_tz":-60,"elapsed":827,"user":{"displayName":"Francisco del Valle Bas","photoUrl":"","userId":"13762240210727807878"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["max(history.history['val_acc'])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9056603796077225"]},"metadata":{"tags":[]},"execution_count":109}]},{"metadata":{"id":"U5WQWoVyemES","colab_type":"code","colab":{}},"cell_type":"code","source":["model_m.save('model_save_medical.h5')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NfOrtfRcyErh","colab_type":"code","colab":{}},"cell_type":"code","source":["plt(history.history['loss'], label = 'loss') \n","plt(history.history['val_loss'], label = 'val_loss') \n","plt.legend()\n","plt.show()\n","\n","\n","plt(history.history['acc'], label = 'acc') \n","plt(history.history['val_acc'], label = 'val_acc') \n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0o7Q1FP9yf-Y","colab_type":"code","colab":{}},"cell_type":"code","source":["from matplotlib.pyplot import plot as plt\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PZ7qooV94tfQ","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}